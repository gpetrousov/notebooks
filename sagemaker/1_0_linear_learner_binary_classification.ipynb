{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Linear Learner with MNIST\n",
    "\n",
    "We're going to use AWS' built-in Linear Learner algorithm for a binary classification problem on the MNIST dataset. Following, we're going to fit the model to predict whether handwriten digit is 0 (zero) or not.\n",
    "\n",
    "I ran this notebook on a `ml.t3.medium` and used additional instances for the manual model training and automatic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Making a Binary Prediction of Whether a Handwritten Digit is a 0**_\n",
    "\n",
    "1. [Introduction](#Introduction)\n",
    "2. [Prerequisites and Preprocessing](#Prequisites-and-Preprocessing)\n",
    "   1. [Permissions and environment variables](#Permissions-and-environment-variables)\n",
    "   2. [Data ingestion](#Data-ingestion)\n",
    "   3. [Data inspection](#Data-inspection)\n",
    "   4. [Data conversion](#Data-conversion)\n",
    "3. [Training the linear model](#Training-the-linear-model)\n",
    "   1. [Training the Linear Learner model with SageMaker Training](#Training-with-sagemaker-training)\n",
    "   2. [Training with Automatic Model Tuning (HPO)](#Training-with-automatic-model-tuning-HPO)\n",
    "4. [Set up hosting for the model](#Set-up-hosting-for-the-model)\n",
    "5. [Validate the model for use](#Validate-the-model-for-use)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Welcome to our example introducing Amazon SageMaker's Linear Learner Algorithm!  Today, we're analyzing the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset which consists of images of handwritten digits, from zero to nine.  We'll use the individual pixel values from each 28 x 28 grayscale image to predict a yes or no label of whether the digit is a 0 or some other digit (1, 2, 3, ... 9).\n",
    "\n",
    "The method that we'll use is a linear binary classifier.  Linear models are supervised learning algorithms used for solving either classification or regression problems.  As input, the model is given labeled examples ( **`x`**, `y`). **`x`** is a high dimensional vector and `y` is a numeric label.  Since we are doing binary classification, the algorithm expects the label to be either 0 or 1 (but Amazon SageMaker Linear Learner also supports regression on continuous values of `y`).  The algorithm learns a linear function, or linear threshold function for classification, mapping the vector **`x`** to an approximation of the label `y`.\n",
    "\n",
    "Amazon SageMaker's Linear Learner algorithm extends upon typical linear models by training many models in parallel, in a computationally efficient manner.  Each model has a different set of hyperparameters, and then the algorithm finds the set that optimizes a specific criteria.  This can provide substantially more accurate models than typical linear algorithms at the same, or lower, cost.\n",
    "\n",
    "To get started, we need to set up the environment with a few prerequisite steps, for permissions, configurations, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/linear_learner_mnist_2024-05-21\n",
      "ip-172-16-62-221.eu-west-1.compute.internal\n"
     ]
    }
   ],
   "source": [
    "# I'm using SageMaker Notebook, so everything is running on an unmanaged EC2 instance\n",
    "!pwd\n",
    "!hostname"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prequisites and Preprocessing\n",
    "\n",
    "### Permissions and environment variables\n",
    "\n",
    "_This notebook was created and tested on an ml.t3.medium notebook instance._\n",
    "\n",
    "Let's start by specifying:\n",
    "\n",
    "- The S3 buckets and prefixes that you want to use for training and model data and where original data is located.  These should be within the same region as the Notebook Instance, training, and hosting.\n",
    "- The IAM role arn used to give training and hosting access to your data. See the documentation for how to create these.  Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the boto regexp with a the appropriate full IAM role arn string(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (2.219.0)\n",
      "Collecting sagemaker\n",
      "  Downloading sagemaker-2.221.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (23.2.0)\n",
      "Requirement already satisfied: boto3<2.0,>=1.33.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.34.101)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.22.4)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.25.3)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (21.3)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: pathos in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.3.2)\n",
      "Requirement already satisfied: schema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (0.7.7)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.0.1)\n",
      "Requirement already satisfied: jsonschema in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.21.1)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.2.0)\n",
      "Requirement already satisfied: tblib<4,>=1.7.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (3.0.0)\n",
      "Requirement already satisfied: urllib3<3.0.0,>=1.26.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.2.1)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (2.31.0)\n",
      "Requirement already satisfied: docker in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (6.1.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (4.66.2)\n",
      "Requirement already satisfied: psutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from sagemaker) (5.9.8)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.101 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.34.101)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from boto3<2.0,>=1.33.3->sagemaker) (0.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker) (3.17.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from packaging>=20.0->sagemaker) (3.1.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from docker->sagemaker) (1.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests->sagemaker) (2024.2.2)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from google-pasta->sagemaker) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from jsonschema->sagemaker) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pandas->sagemaker) (2024.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (1.7.6.8)\n",
      "Requirement already satisfied: dill>=0.3.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.8)\n",
      "Requirement already satisfied: pox>=0.3.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.3.4)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pathos->sagemaker) (0.70.16)\n",
      "Downloading sagemaker-2.221.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sagemaker\n",
      "  Attempting uninstall: sagemaker\n",
      "    Found existing installation: sagemaker 2.219.0\n",
      "    Uninstalling sagemaker-2.219.0:\n",
      "      Successfully uninstalled sagemaker-2.219.0\n",
      "Successfully installed sagemaker-2.221.0\n"
     ]
    }
   ],
   "source": [
    "! pip install --upgrade sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "isConfigCell": true,
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# The remote S3 bucket where the original mnist data is downloaded from and stored.\n",
    "downloaded_data_bucket = f\"sagemaker-example-files-prod-{region}\"\n",
    "downloaded_data_prefix = \"datasets/image/MNIST\"\n",
    "\n",
    "# One bucket to rule them all - creates bucket if it does not exist\n",
    "# https://sagemaker.readthedocs.io/en/stable/api/utility/session.html#sagemaker.session.Session.default_bucket\n",
    "bucket = sess.default_bucket()\n",
    "prefix = \"sagemaker/linear_learner_binary_classification\"\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data ingestion\n",
    "\n",
    "Next, we read the MNIST dataset [1] from an existing repository into memory, for preprocessing prior to training. It was downloaded from this [link](http://deeplearning.net/data/mnist/mnist.pkl.gz) and stored on the `downloaded_data_bucket`. Processing could be done *in situ* by Amazon Athena, Apache Spark in Amazon EMR, Amazon Redshift, etc., assuming the dataset is present in the appropriate location. Then, the next step would be to transfer the data to S3 for use in training. For small datasets, such as this one, reading into memory isn't onerous, though it would be for larger datasets.\n",
    "> [1] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, November 1998."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 812 ms, sys: 348 ms, total: 1.16 s\n",
      "Wall time: 2.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pickle, gzip, numpy, json\n",
    "\n",
    "# Load the dataset\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(downloaded_data_bucket, f\"{downloaded_data_prefix}/mnist.pkl.gz\", \"mnist.pkl.gz\")\n",
    "with gzip.open(\"mnist.pkl.gz\", \"rb\") as f:\n",
    "    train_set, valid_set, test_set = pickle.load(f, encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data inspection\n",
    "\n",
    "Once the dataset is imported, it's typical as part of the machine learning process to inspect the data, understand the distributions, and determine what type(s) of preprocessing might be needed. You can perform those tasks right here in the notebook. As an example, let's go ahead and look at one of the digits that is part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (2, 10)\n",
    "\n",
    "\n",
    "def show_images_sample(imgs, lbls, n_row=3, n_col=3):\n",
    "    \"\"\" Create a matplotlib plot to show images with their labels. \"\"\"\n",
    "    _, axs = plt.subplots(n_row, n_col, figsize=(10, 10))\n",
    "    axs = axs.flatten()\n",
    "    for img, lbl, ax in zip(imgs, lbls, axs):\n",
    "        ax.set_axis_off()\n",
    "        ax.title.set_text(lbl)\n",
    "        ax.imshow(img.reshape(28, 28), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_range = range(0,9)\n",
    "sample_images = train_set[0][img_range]\n",
    "sample_labels = train_set[1][img_range]\n",
    "show_images_sample(sample_images, sample_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data conversion\n",
    "\n",
    "Since algorithms have particular input and output requirements, converting the dataset is also part of the process that a data scientist goes through prior to initiating training. In this particular case, the Amazon SageMaker implementation of Linear Learner takes recordIO-wrapped protobuf, where the data we have today is a pickle-ized numpy array on disk.\n",
    "\n",
    "Most of the conversion effort is handled by the Amazon SageMaker Python SDK, imported as `sagemaker` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "import numpy as np\n",
    "import sagemaker.amazon.common as smac\n",
    "\n",
    "# Identity only zeros and set the label to 1\n",
    "train_set_vectors = np.array([t.tolist() for t in train_set[0]]).astype(\"float32\")\n",
    "train_set_labels = np.where(np.array([t.tolist() for t in train_set[1]]) == 0, 1, 0).astype(\"float32\")\n",
    "\n",
    "# Same for validation\n",
    "validation_set_vectors = np.array([t.tolist() for t in valid_set[0]]).astype(\"float32\")\n",
    "validation_set_labels = np.where(np.array([t.tolist() for t in valid_set[1]]) == 0, 1, 0).astype(\"float32\")\n",
    "\n",
    "# LinearLearner requires the records to be in protobuf recordIO format - binary\n",
    "train_set_buf = io.BytesIO()\n",
    "validation_set_buf = io.BytesIO()\n",
    "\n",
    "smac.write_numpy_to_dense_tensor(train_set_buf, train_set_vectors, train_set_labels)\n",
    "smac.write_numpy_to_dense_tensor(validation_set_buf, validation_set_vectors, validation_set_labels)\n",
    "\n",
    "train_set_buf.seek(0)\n",
    "validation_set_buf.seek(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload training data\n",
    "Now that we've created our recordIO-wrapped protobuf, we'll need to upload it to S3, so that Amazon SageMaker training can use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://sagemaker-eu-west-1-560303188884/sagemaker/linear_learner_binary_classification/train/recordio-pb-data\n",
      "uploaded validation data location: s3://sagemaker-eu-west-1-560303188884/sagemaker/linear_learner_binary_classification/validation/recordio-pb-data\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "key = \"recordio-pb-data\"\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"train\", key)).upload_fileobj(train_set_buf)\n",
    "boto3.resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"validation\", key)).upload_fileobj(validation_set_buf)\n",
    "\n",
    "s3_train_data = f\"s3://{bucket}/{prefix}/train/{key}\"\n",
    "s3_validation_data = f\"s3://{bucket}/{prefix}/validation/{key}\"\n",
    "\n",
    "print(f\"uploaded training data location: {s3_train_data}\")\n",
    "print(f\"uploaded validation data location: {s3_validation_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also setup an output S3 location for the model artifact that will be output as the result of training with the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://sagemaker-eu-west-1-560303188884/sagemaker/linear_learner_binary_classification/output\n"
     ]
    }
   ],
   "source": [
    "output_location = f\"s3://{bucket}/{prefix}/output\"\n",
    "print(f\"training artifacts will be uploaded to: {output_location}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the linear model\n",
    "\n",
    "Once we have the data preprocessed and available in the correct format for training, the next step is to actually train the model using the data. Since this data is relatively small, it isn't meant to show off the performance of the Linear Learner training algorithm, although we have tested it on multi-terabyte datasets.\n",
    "\n",
    "Training can be done by either calling SageMaker Training with a set of hyperparameters values to train with, or by leveraging SageMaker Automatic Model Tuning ([AMT](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)). AMT, also known as hyperparameter tuning (HPO), finds the best version of a model by running many training jobs on your dataset using the algorithm and ranges of hyperparameters that you specify. It then chooses the hyperparameter values that result in a model that performs the best, as measured by a metric that you choose.\n",
    "\n",
    "In this notebook, both methods are used for demonstration purposes, but the model that the HPO job creates is the one that is eventually hosted. You can instead choose to deploy the model created by the standalone training job by changing the below variable `deploy_amt_model` to False.\n",
    "\n",
    "### Training with SageMaker Training\n",
    "\n",
    "We'll use the Amazon SageMaker Python SDK to kick off training, and monitor status until it is completed.  In this example that takes between 7 and 11 minutes. Despite the dataset being small, provisioning hardware and loading the algorithm container take time upfront.\n",
    "\n",
    "First, let's specify our container. We retrieve the image for the Linear Learner Algorithm according to the region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"linear-learner\")\n",
    "deploy_amt_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an [estimator from the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html) using the Linear Learner container image and we setup the training parameters and hyperparameters configuration. Notice:\n",
    "- `feature_dim` is set to 784, which is the number of pixels in each 28 x 28 image.\n",
    "- `predictor_type` is set to 'binary_classifier' since we are trying to predict whether the image is or is not a 0.\n",
    "- `mini_batch_size` is set to 200.  This value can be tuned for relatively minor improvements in fit and speed, but selecting a reasonable value relative to the dataset is appropriate in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: linear-learner-2024-05-22-11-38-32-551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 11:38:32 Starting - Starting the training job...\n",
      "2024-05-22 11:38:47 Starting - Preparing the instances for training...\n",
      "2024-05-22 11:39:13 Downloading - Downloading input data...\n",
      "2024-05-22 11:39:58 Downloading - Downloading the training image.........\n",
      "2024-05-22 11:41:19 Training - Training image download completed. Training in progress..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34mRunning default environment configuration script\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:28 INFO 139660246460224] Reading default configuration from /opt/amazon/lib/python3.8/site-packages/algorithm/resources/default-input.json: {'mini_batch_size': '1000', 'epochs': '15', 'feature_dim': 'auto', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:28 INFO 139660246460224] Merging with provided configuration from /opt/ml/input/config/hyperparameters.json: {'epochs': '5', 'feature_dim': '784', 'mini_batch_size': '200', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:28 INFO 139660246460224] Final configuration: {'mini_batch_size': '200', 'epochs': '5', 'feature_dim': '784', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/mxnet/model.py:97: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if num_device is 1 and 'dist' not in kvstore:\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:495: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if cons['type'] is 'ineq':\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.8/site-packages/scipy/optimize/_shgo.py:743: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if len(self.X_min) is not 0:\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 WARNING 139660246460224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Final configuration: {'mini_batch_size': '200', 'epochs': '5', 'feature_dim': '784', 'use_bias': 'true', 'binary_classifier_model_selection_criteria': 'accuracy', 'f_beta': '1.0', 'target_recall': '0.8', 'target_precision': '0.8', 'num_models': 'auto', 'num_calibration_samples': '10000000', 'init_method': 'uniform', 'init_scale': '0.07', 'init_sigma': '0.01', 'init_bias': '0.0', 'optimizer': 'auto', 'loss': 'auto', 'margin': '1.0', 'quantile': '0.5', 'loss_insensitivity': '0.01', 'huber_delta': '1.0', 'num_classes': '1', 'accuracy_top_k': '3', 'wd': 'auto', 'l1': 'auto', 'momentum': 'auto', 'learning_rate': 'auto', 'beta_1': 'auto', 'beta_2': 'auto', 'bias_lr_mult': 'auto', 'bias_wd_mult': 'auto', 'use_lr_scheduler': 'true', 'lr_scheduler_step': 'auto', 'lr_scheduler_factor': 'auto', 'lr_scheduler_minimum_lr': 'auto', 'positive_example_weight_mult': '1.0', 'balance_multiclass_weights': 'false', 'normalize_data': 'true', 'normalize_label': 'auto', 'unbias_data': 'auto', 'unbias_label': 'auto', 'num_point_for_scaler': '10000', '_kvstore': 'auto', '_num_gpus': 'auto', '_num_kv_servers': 'auto', '_log_level': 'info', '_tuning_objective_metric': '', 'early_stopping_patience': '3', 'early_stopping_tolerance': '0.001', '_enable_profiler': 'false', 'predictor_type': 'binary_classifier'}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 WARNING 139660246460224] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 7 is a worker.\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Using default worker.\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Checkpoint loading and saving are disabled.\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:31.120] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 26, \"num_examples\": 1, \"num_bytes\": 636800}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Create Store: local\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:31.394] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 273, \"num_examples\": 51, \"num_bytes\": 32476800}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Scaler algorithm parameters\n",
      " <algorithm.scaler.ScalerAlgorithmStable object at 0x7f049f259850>\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Scaling model computed with parameters:\n",
      " {'stdev_label': None, 'stdev_weight': \u001b[0m\n",
      "\u001b[34m[1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 3.94492550e-03\n",
      " 1.04610855e-02 1.33176269e-02 1.02671087e-02 1.89491250e-02\n",
      " 1.65359322e-02 1.81397479e-02 1.77312214e-02 1.80720985e-02\n",
      " 2.26263870e-02 1.72949098e-02 1.77441761e-02 1.38624832e-02\n",
      " 1.54940551e-02 9.07990150e-03 7.73912016e-03 7.61912158e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 2.24319263e-03 4.84585791e-04 1.97246275e-03 4.55508707e-03\n",
      " 2.29639579e-02 3.39448415e-02 4.29402180e-02 5.23685887e-02\n",
      " 6.82234913e-02 7.98171237e-02 8.88206214e-02 1.01305366e-01\n",
      " 1.15898423e-01 1.12989835e-01 9.80169475e-02 8.25162008e-02\n",
      " 5.89759052e-02 4.34567295e-02 2.49874219e-02 1.34935491e-02\n",
      " 4.03929362e-03 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 3.77784553e-03 1.69358458e-02 2.65588202e-02 3.42243798e-02\n",
      " 5.25780693e-02 6.86879233e-02 9.47839096e-02 1.18634902e-01\n",
      " 1.40737429e-01 1.66125149e-01 1.85117915e-01 2.01920375e-01\n",
      " 2.06296414e-01 1.97139218e-01 1.73980132e-01 1.44603163e-01\n",
      " 1.06258735e-01 7.99237639e-02 5.08462936e-02 2.65238583e-02\n",
      " 1.36450613e-02 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 3.20059783e-03\n",
      " 1.45901926e-02 3.13075073e-02 4.58937474e-02 7.50448108e-02\n",
      " 1.05263487e-01 1.42169774e-01 1.86635748e-01 2.27824897e-01\n",
      " 2.65833706e-01 3.00070584e-01 3.25894147e-01 3.41829926e-01\n",
      " 3.42463762e-01 3.27946275e-01 3.03464592e-01 2.60635525e-01\n",
      " 2.05971986e-01 1.55582175e-01 1.13750860e-01 7.58975968e-02\n",
      " 4.29635681e-02 1.47907427e-02 3.48081696e-04 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.93935696e-03 1.51115656e-02\n",
      " 3.29358652e-02 6.57071769e-02 9.60143283e-02 1.35235637e-01\n",
      " 1.82123125e-01 2.31933147e-01 2.83096194e-01 3.29145193e-01\n",
      " 3.67008448e-01 3.99231106e-01 4.17853862e-01 4.24342513e-01\n",
      " 4.26379174e-01 4.17568326e-01 3.94363761e-01 3.55644882e-01\n",
      " 3.03377479e-01 2.44013295e-01 1.83915734e-01 1.32495791e-01\n",
      " 8.74551907e-02 4.33507822e-02 1.33556416e-02 6.96163392e-04\n",
      " 1.00000000e+00 1.00000000e+00 7.76072918e-03 2.76757479e-02\n",
      " 5.67227043e-02 9.11811665e-02 1.34879202e-01 1.90676540e-01\n",
      " 2.46868506e-01 3.02129209e-01 3.53216469e-01 3.92389953e-01\n",
      " 4.16605562e-01 4.31067705e-01 4.37365025e-01 4.41249490e-01\n",
      " 4.39440429e-01 4.39221919e-01 4.30656374e-01 4.07722294e-01\u001b[0m\n",
      "\u001b[34m/opt/amazon/python3.8/lib/python3.8/subprocess.py:848: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n",
      " 3.61761272e-01 3.06319296e-01 2.40859449e-01 1.77256167e-01\n",
      " 1.22995712e-01 7.14610592e-02 3.02156471e-02 1.18679544e-02\n",
      " 1.81776099e-03 9.33173113e-03 1.80900171e-02 4.36167121e-02\n",
      " 7.67053217e-02 1.23607144e-01 1.74079359e-01 2.33128011e-01\n",
      " 2.93940902e-01 3.50558162e-01 3.93199652e-01 4.15627837e-01\n",
      " 4.25236702e-01 4.29629087e-01 4.30348128e-01 4.29715633e-01\n",
      " 4.31071222e-01 4.32865858e-01 4.31941420e-01 4.24364537e-01\n",
      " 3.96579325e-01 3.47653896e-01 2.81905383e-01 2.12364540e-01\n",
      " 1.46784306e-01 9.10512730e-02 4.09692377e-02 1.10720564e-02\n",
      " 7.38706766e-03 1.69502832e-02 2.96603944e-02 5.78092076e-02\n",
      " 1.05509877e-01 1.51767865e-01 2.06245676e-01 2.70226508e-01\n",
      " 3.32466841e-01 3.85342121e-01 4.15692836e-01 4.29783225e-01\n",
      " 4.34012383e-01 4.35559571e-01 4.35787708e-01 4.32419538e-01\n",
      " 4.32698786e-01 4.35421079e-01 4.36579973e-01 4.31350917e-01\n",
      " 4.15372491e-01 3.69549870e-01 3.01578254e-01 2.22329885e-01\n",
      " 1.49137840e-01 9.14694145e-02 3.23920399e-02 8.82186554e-03\n",
      " 1.19894824e-03 1.90961286e-02 3.56134474e-02 6.87012076e-02\n",
      " 1.13878332e-01 1.67845502e-01 2.28681266e-01 2.96960264e-01\n",
      " 3.59889030e-01 4.04147655e-01 4.27901119e-01 4.35145408e-01\n",
      " 4.36418921e-01 4.31494981e-01 4.27002698e-01 4.22120482e-01\n",
      " 4.27684844e-01 4.33761090e-01 4.34772104e-01 4.32158500e-01\n",
      " 4.15939212e-01 3.72851223e-01 3.00387651e-01 2.07922608e-01\n",
      " 1.28391027e-01 6.42759129e-02 2.19067242e-02 5.73158218e-03\n",
      " 1.00000000e+00 2.01530941e-02 3.94741297e-02 6.93644360e-02\n",
      " 1.13405839e-01 1.70645282e-01 2.35999882e-01 3.05523038e-01\n",
      " 3.72269690e-01 4.12820429e-01 4.31253672e-01 4.33602810e-01\n",
      " 4.23717797e-01 4.09735233e-01 4.04385388e-01 4.11280185e-01\n",
      " 4.22015309e-01 4.29675877e-01 4.30581391e-01 4.30687040e-01\n",
      " 4.07417446e-01 3.59438032e-01 2.84420550e-01 1.92011282e-01\n",
      " 1.09981179e-01 4.64483313e-02 1.58791281e-02 2.04981444e-03\n",
      " 1.00000000e+00 1.04851592e-02 3.80173847e-02 6.77681640e-02\n",
      " 1.07945666e-01 1.71286166e-01 2.40526810e-01 3.16523194e-01\n",
      " 3.82934034e-01 4.19950128e-01 4.31718022e-01 4.27304059e-01\n",
      " 4.09066856e-01 3.94010305e-01 4.01941001e-01 4.14808959e-01\n",
      " 4.21882480e-01 4.28273916e-01 4.29794133e-01 4.26058590e-01\n",
      " 3.91682118e-01 3.35908264e-01 2.68548399e-01 1.87748045e-01\n",
      " 1.04305372e-01 4.02241386e-02 2.12533344e-02 1.08292082e-03\n",
      " 1.00000000e+00 1.00112176e-02 2.82707363e-02 5.37265576e-02\n",
      " 9.87592936e-02 1.71164855e-01 2.50810295e-01 3.33866268e-01\n",
      " 3.94889355e-01 4.24917608e-01 4.31839973e-01 4.25715894e-01\n",
      " 4.08126831e-01 4.02041048e-01 4.21552151e-01 4.30972755e-01\n",
      " 4.29834664e-01 4.32951361e-01 4.35623735e-01 4.18909818e-01\n",
      " 3.77192348e-01 3.21708620e-01 2.62223452e-01 1.94190100e-01\n",
      " 1.12322643e-01 3.89801674e-02 1.99374650e-02 3.71287018e-03\n",
      " 1.00000000e+00 9.86280106e-03 1.81496162e-02 3.92598845e-02\n",
      " 9.34294462e-02 1.76559284e-01 2.69591689e-01 3.51013362e-01\n",
      " 4.02812719e-01 4.27507520e-01 4.32988375e-01 4.23787117e-01\n",
      " 4.16044772e-01 4.23496246e-01 4.43873614e-01 4.37031209e-01\n",
      " 4.29811329e-01 4.35970992e-01 4.35601205e-01 4.11843717e-01\n",
      " 3.69036704e-01 3.19448829e-01 2.65287995e-01 2.01888576e-01\n",
      " 1.20717429e-01 4.04090285e-02 7.50047434e-03 1.00000000e+00\n",
      " 1.00000000e+00 4.67976369e-03 9.96531639e-03 3.44210491e-02\n",
      " 9.45271328e-02 1.90941051e-01 2.84894913e-01 3.61630678e-01\n",
      " 4.07279700e-01 4.27376866e-01 4.29911733e-01 4.23774391e-01\n",
      " 4.22459662e-01 4.35994923e-01 4.43703175e-01 4.27118272e-01\n",
      " 4.26644385e-01 4.38567311e-01 4.34852242e-01 4.10224825e-01\n",
      " 3.73937458e-01 3.24929148e-01 2.68227905e-01 2.05017433e-01\n",
      " 1.22506626e-01 4.50176559e-02 7.62108993e-03 1.00000000e+00\n",
      " 1.00000000e+00 2.32054386e-04 9.20575298e-03 3.74859497e-02\n",
      " 1.00403078e-01 2.08951607e-01 2.98761904e-01 3.63920152e-01\n",
      " 4.05923426e-01 4.26199824e-01 4.26035821e-01 4.22738880e-01\n",
      " 4.27782774e-01 4.38919425e-01 4.38770294e-01 4.24572170e-01\n",
      " 4.33793157e-01 4.40616667e-01 4.30870563e-01 4.08146024e-01\n",
      " 3.76872540e-01 3.28658342e-01 2.71661043e-01 2.04069793e-01\n",
      " 1.23419538e-01 4.75159809e-02 1.87039636e-02 2.32054386e-04\n",
      " 1.00000000e+00 3.55816842e-03 1.46121653e-02 4.30633724e-02\n",
      " 1.16337217e-01 2.23566353e-01 3.06311727e-01 3.64136040e-01\n",
      " 3.98461193e-01 4.14042771e-01 4.14940715e-01 4.18315828e-01\n",
      " 4.31104004e-01 4.42299932e-01 4.39964354e-01 4.33156490e-01\n",
      " 4.37774807e-01 4.34804469e-01 4.26190317e-01 4.09637958e-01\n",
      " 3.79669040e-01 3.29323441e-01 2.66756743e-01 1.96854621e-01\n",
      " 1.22142516e-01 5.29063754e-02 2.36502886e-02 4.25433216e-04\n",
      " 1.00000000e+00 2.75275926e-03 2.19910592e-02 5.58153689e-02\n",
      " 1.35455310e-01 2.38594130e-01 3.09096992e-01 3.59269977e-01\n",
      " 3.87636125e-01 3.99718255e-01 4.03454840e-01 4.12936360e-01\n",
      " 4.24752861e-01 4.33075130e-01 4.37052727e-01 4.37283844e-01\n",
      " 4.35459405e-01 4.29879934e-01 4.24114525e-01 4.09037948e-01\n",
      " 3.77857178e-01 3.26454788e-01 2.58835465e-01 1.87275320e-01\n",
      " 1.21168144e-01 6.50033727e-02 2.86698006e-02 3.63503420e-03\n",
      " 1.00000000e+00 6.96163275e-04 2.49386393e-02 7.23880157e-02\n",
      " 1.58358768e-01 2.51288056e-01 3.17836136e-01 3.60069126e-01\n",
      " 3.79850537e-01 3.91518563e-01 4.01267678e-01 4.09322888e-01\n",
      " 4.14236486e-01 4.26342309e-01 4.34745014e-01 4.33905691e-01\n",
      " 4.30959105e-01 4.31691229e-01 4.28531677e-01 4.09231365e-01\n",
      " 3.69187117e-01 3.15112293e-01 2.44048655e-01 1.71371251e-01\n",
      " 1.10449135e-01 5.60242236e-02 1.53466230e-02 6.76992768e-03\n",
      " 1.00000000e+00 1.00000000e+00 3.05887461e-02 8.80458131e-02\n",
      " 1.71716914e-01 2.62007117e-01 3.30397874e-01 3.69256526e-01\n",
      " 3.89117181e-01 4.01139468e-01 4.13360953e-01 4.20257658e-01\n",
      " 4.22717273e-01 4.31972921e-01 4.35091466e-01 4.33622122e-01\n",
      " 4.31084007e-01 4.34083730e-01 4.26372021e-01 3.97604764e-01\n",
      " 3.52505296e-01 2.89563209e-01 2.18649939e-01 1.49916708e-01\n",
      " 9.37407240e-02 4.48708124e-02 1.23545434e-02 4.28988039e-03\n",
      " 1.00000000e+00 1.50835409e-03 3.47997397e-02 9.18959305e-02\n",
      " 1.69907510e-01 2.56383538e-01 3.31546009e-01 3.78374457e-01\n",
      " 4.03178424e-01 4.17098701e-01 4.26328897e-01 4.31362152e-01\n",
      " 4.33458388e-01 4.35984612e-01 4.35091168e-01 4.35326993e-01\n",
      " 4.35005218e-01 4.31360275e-01 4.13945585e-01 3.78624141e-01\n",
      " 3.21096003e-01 2.52549678e-01 1.85978875e-01 1.25768527e-01\n",
      " 7.87079036e-02 3.45092155e-02 1.39352623e-02 1.93378725e-03\n",
      " 1.00000000e+00 2.78465310e-03 3.22530977e-02 7.88924918e-02\n",
      " 1.44034386e-01 2.30809659e-01 3.14300448e-01 3.74641836e-01\n",
      " 4.07947451e-01 4.27144140e-01 4.35362130e-01 4.33135808e-01\n",
      " 4.34356421e-01 4.31999445e-01 4.34135765e-01 4.35558110e-01\n",
      " 4.28441972e-01 4.14655238e-01 3.84276271e-01 3.32879990e-01\n",
      " 2.70405531e-01 2.07401454e-01 1.49886608e-01 9.68566611e-02\n",
      " 6.16969466e-02 2.89664306e-02 1.14726946e-02 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 2.16943659e-02 5.37078306e-02\n",
      " 1.02763742e-01 1.73823819e-01 2.57987916e-01 3.33273381e-01\n",
      " 3.89094591e-01 4.21987742e-01 4.38015908e-01 4.42052513e-01\n",
      " 4.38766658e-01 4.37678665e-01 4.38338399e-01 4.32226747e-01\n",
      " 4.11157072e-01 3.78847182e-01 3.30883265e-01 2.71805763e-01\n",
      " 2.11537763e-01 1.60093278e-01 1.13874733e-01 7.19486699e-02\n",
      " 4.39616479e-02 2.10775882e-02 6.10366603e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 5.77727053e-03 2.51513571e-02\n",
      " 6.01222143e-02 1.08414136e-01 1.74756184e-01 2.49787211e-01\n",
      " 3.23381543e-01 3.76828671e-01 4.10625458e-01 4.28288579e-01\n",
      " 4.30554032e-01 4.25631940e-01 4.18370575e-01 3.93252224e-01\n",
      " 3.55806261e-01 3.05945784e-01 2.52188265e-01 2.03128546e-01\n",
      " 1.57345042e-01 1.15941033e-01 7.96129629e-02 5.03237098e-02\n",
      " 1.66886058e-02 3.65128578e-03 3.24876350e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.63300186e-02\n",
      " 3.99022102e-02 6.71634078e-02 1.07849061e-01 1.58636972e-01\n",
      " 2.14336604e-01 2.74235785e-01 3.19748670e-01 3.44148219e-01\n",
      " 3.49004447e-01 3.46731484e-01 3.29878896e-01 2.94327945e-01\n",
      " 2.59320974e-01 2.18367904e-01 1.79865524e-01 1.45078033e-01\n",
      " 1.16880730e-01 8.47071484e-02 5.53058349e-02 3.47583294e-02\n",
      " 1.50805498e-02 1.35365094e-03 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 2.45967391e-03\n",
      " 1.70110669e-02 4.11987118e-02 6.91738352e-02 1.01292245e-01\n",
      " 1.44580290e-01 1.82481498e-01 2.12960392e-01 2.19844192e-01\n",
      " 2.22073749e-01 2.21406013e-01 2.08605841e-01 1.86790422e-01\n",
      " 1.71107888e-01 1.48116753e-01 1.21893883e-01 1.00215897e-01\n",
      " 7.93611184e-02 5.65856993e-02 3.35968845e-02 2.18519438e-02\n",
      " 5.58676105e-03 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.46967848e-03\n",
      " 1.05320141e-02 2.14112904e-02 4.39937375e-02 6.59096837e-02\n",
      " 9.34475884e-02 1.14821352e-01 1.27970278e-01 1.30696684e-01\n",
      " 1.26551583e-01 1.26627609e-01 1.26468301e-01 1.06794536e-01\n",
      " 9.68687087e-02 8.43336359e-02 7.16911405e-02 5.94058782e-02\n",
      " 4.67881113e-02 3.16491798e-02 1.87638719e-02 7.71086058e-03\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00\n",
      " 1.00000000e+00 6.84560649e-03 1.00246007e-02 1.74784493e-02\n",
      " 2.19308790e-02 2.16455013e-02 2.81812716e-02 3.65256816e-02\n",
      " 4.40249480e-02 4.45496589e-02 4.55292128e-02 3.93585563e-02\n",
      " 3.22563127e-02 2.38721371e-02 2.29482837e-02 1.43505000e-02\n",
      " 1.28365206e-02 8.07273109e-03 7.92295765e-03 1.00000000e+00\n",
      " 1.00000000e+00 1.00000000e+00 1.00000000e+00 1.00000000e+00]\u001b[0m\n",
      "\u001b[34m<NDArray 784 @cpu(0)>, 'mean_label': None, 'mean_weight': \u001b[0m\n",
      "\u001b[34m[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.90625028e-05\n",
      " 1.32889123e-04 2.12545914e-04 2.20588292e-04 4.37346840e-04\n",
      " 4.09773231e-04 4.72962623e-04 4.15517774e-04 5.31939266e-04\n",
      " 6.38020982e-04 4.27389663e-04 3.56923905e-04 3.15946672e-04\n",
      " 3.02159897e-04 1.42080273e-04 1.08379281e-04 7.54442444e-05\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 2.22120143e-05 6.51041682e-06 1.95312514e-05 1.03017774e-04\n",
      " 7.32230430e-04 1.57130824e-03 2.47051148e-03 3.84382624e-03\n",
      " 6.16153423e-03 8.27282388e-03 1.08363954e-02 1.39410989e-02\n",
      " 1.73958354e-02 1.66976880e-02 1.28461989e-02 8.66957568e-03\n",
      " 4.60631074e-03 2.31617643e-03 9.10692499e-04 2.82245717e-04\n",
      " 5.93596778e-05 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 4.82536743e-05 4.38112766e-04 9.07628739e-04 1.66743260e-03\n",
      " 3.62936594e-03 6.43727044e-03 1.21074598e-02 1.88530199e-02\n",
      " 2.66567096e-02 3.65372300e-02 4.59099337e-02 5.50080538e-02\n",
      " 5.73376231e-02 5.18887974e-02 4.03002501e-02 2.76489742e-02\n",
      " 1.52611826e-02 8.10087286e-03 3.67302471e-03 1.11711072e-03\n",
      " 3.91773909e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.48069877e-05\n",
      " 3.41222534e-04 1.71568606e-03 3.50030605e-03 8.14491417e-03\n",
      " 1.56544875e-02 2.86845118e-02 4.83670309e-02 7.23407120e-02\n",
      " 1.01020999e-01 1.33289650e-01 1.62758857e-01 1.81522310e-01\n",
      " 1.83595344e-01 1.66121781e-01 1.35376498e-01 9.75677967e-02\n",
      " 5.99628538e-02 3.41015644e-02 1.84110757e-02 8.35784432e-03\n",
      " 2.97602639e-03 4.69132967e-04 3.44669206e-06 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.91053893e-05 3.81433871e-04\n",
      " 1.75551476e-03 5.74257039e-03 1.25919124e-02 2.49088537e-02\n",
      " 4.51240875e-02 7.51478225e-02 1.15662917e-01 1.63785979e-01\n",
      " 2.17636332e-01 2.78250545e-01 3.28077555e-01 3.55426341e-01\n",
      " 3.54569584e-01 3.26203197e-01 2.71575481e-01 2.04266593e-01\n",
      " 1.37503117e-01 8.55721459e-02 4.86711077e-02 2.50899959e-02\n",
      " 1.13591421e-02 3.13763833e-03 4.08241438e-04 6.89338503e-06\n",
      " 0.00000000e+00 0.00000000e+00 1.27910535e-04 1.17225817e-03\n",
      " 4.43704007e-03 1.12787224e-02 2.50107199e-02 4.93233055e-02\n",
      " 8.46358016e-02 1.33169040e-01 1.96388662e-01 2.64108837e-01\n",
      " 3.33429158e-01 4.03901666e-01 4.60013002e-01 4.86333936e-01\n",
      " 4.79071230e-01 4.41563368e-01 3.81979197e-01 3.01045179e-01\n",
      " 2.11790368e-01 1.39361590e-01 8.36182684e-02 4.40996476e-02\n",
      " 2.17700712e-02 7.55936047e-03 1.46790745e-03 2.66544113e-04\n",
      " 1.79993876e-05 1.64292273e-04 4.95174667e-04 2.76692701e-03\n",
      " 8.63549486e-03 2.04936378e-02 4.16942388e-02 7.59351924e-02\n",
      " 1.28435969e-01 1.97459787e-01 2.75440365e-01 3.52621377e-01\n",
      " 4.23433721e-01 4.82485831e-01 5.17372906e-01 5.28684556e-01\n",
      " 5.20964563e-01 4.98504639e-01 4.51166153e-01 3.74432474e-01\n",
      " 2.80243129e-01 1.89844146e-01 1.15545332e-01 6.26642853e-02\n",
      " 3.01079992e-02 1.19734202e-02 2.55744485e-03 2.16375629e-04\n",
      " 7.31464388e-05 3.79519071e-04 1.17455551e-03 4.91115265e-03\n",
      " 1.47813242e-02 3.07169110e-02 5.83739318e-02 1.04968227e-01\n",
      " 1.70094207e-01 2.52433330e-01 3.39439034e-01 4.15227443e-01\n",
      " 4.66429293e-01 4.86376077e-01 4.85968858e-01 4.78029579e-01\n",
      " 4.78621274e-01 4.82984066e-01 4.66659456e-01 4.05716091e-01\n",
      " 3.17226261e-01 2.20420867e-01 1.33341417e-01 6.87564835e-02\n",
      " 3.04760262e-02 1.17689194e-02 1.78806693e-03 1.41314362e-04\n",
      " 1.18719363e-05 5.61044726e-04 1.90295628e-03 6.23506308e-03\n",
      " 1.71511248e-02 3.74770202e-02 7.15031177e-02 1.26650587e-01\n",
      " 2.02949598e-01 2.94427514e-01 3.79658788e-01 4.32254910e-01\n",
      " 4.38242137e-01 4.15262312e-01 3.93862665e-01 3.87077212e-01\n",
      " 4.06341642e-01 4.39446598e-01 4.44381922e-01 4.01194066e-01\n",
      " 3.18853021e-01 2.19575286e-01 1.30831435e-01 6.14755712e-02\n",
      " 2.33264416e-02 6.70764316e-03 8.67800205e-04 7.88909238e-05\n",
      " 0.00000000e+00 5.25811862e-04 2.00367649e-03 6.22357521e-03\n",
      " 1.70232039e-02 3.90058272e-02 7.54829273e-02 1.36563689e-01\n",
      " 2.24274233e-01 3.16170424e-01 3.88575464e-01 4.07194078e-01\n",
      " 3.71892601e-01 3.31032872e-01 3.14777911e-01 3.29337537e-01\n",
      " 3.65734577e-01 4.14378464e-01 4.22445983e-01 3.82889181e-01\n",
      " 2.95634151e-01 1.97893709e-01 1.14763714e-01 5.18550836e-02\n",
      " 1.68543253e-02 3.42869200e-03 4.43091325e-04 2.02971787e-05\n",
      " 0.00000000e+00 2.07184479e-04 1.94431690e-03 5.79695264e-03\n",
      " 1.55070489e-02 3.86274494e-02 7.87140131e-02 1.48641601e-01\n",
      " 2.41823688e-01 3.33093256e-01 3.86814862e-01 3.75730783e-01\n",
      " 3.25647891e-01 2.93674231e-01 2.95394480e-01 3.27838182e-01\n",
      " 3.76086175e-01 4.22431856e-01 4.14441288e-01 3.60018104e-01\n",
      " 2.64072478e-01 1.69874787e-01 9.94791612e-02 4.76409346e-02\n",
      " 1.53029282e-02 2.47587333e-03 6.41084567e-04 1.07230408e-05\n",
      " 0.00000000e+00 1.35186885e-04 1.09183521e-03 3.96254519e-03\n",
      " 1.31809143e-02 3.91624533e-02 8.78136382e-02 1.66480169e-01\n",
      " 2.61925936e-01 3.49522948e-01 3.84906143e-01 3.62014413e-01\n",
      " 3.17119747e-01 3.07949215e-01 3.40878874e-01 3.86790723e-01\n",
      " 4.38486993e-01 4.57743973e-01 4.20700818e-01 3.38735342e-01\n",
      " 2.38151044e-01 1.52724415e-01 9.33498070e-02 4.89954762e-02\n",
      " 1.73000898e-02 2.29702820e-03 5.73299709e-04 3.67647008e-05\n",
      " 0.00000000e+00 1.09145214e-04 4.70664818e-04 2.36251554e-03\n",
      " 1.21591613e-02 4.23525535e-02 1.01402044e-01 1.85072735e-01\n",
      " 2.78429031e-01 3.58133405e-01 3.83456230e-01 3.63861024e-01\n",
      " 3.43767256e-01 3.75709593e-01 4.27707583e-01 4.77439970e-01\n",
      " 5.08730531e-01 4.91583139e-01 4.22190994e-01 3.21526974e-01\n",
      " 2.25145176e-01 1.49216115e-01 9.45909917e-02 5.30058965e-02\n",
      " 1.96327381e-02 2.45787320e-03 1.63909339e-04 0.00000000e+00\n",
      " 0.00000000e+00 4.63388387e-05 1.23314967e-04 1.82559795e-03\n",
      " 1.24268550e-02 5.01930043e-02 1.13691024e-01 1.98525205e-01\n",
      " 2.87391603e-01 3.53973240e-01 3.77128184e-01 3.71904790e-01\n",
      " 3.87973756e-01 4.50541943e-01 5.05334973e-01 5.47347963e-01\n",
      " 5.45139909e-01 5.03177166e-01 4.16105539e-01 3.13716203e-01\n",
      " 2.25746006e-01 1.54364645e-01 9.82486829e-02 5.54687455e-02\n",
      " 2.02895179e-02 2.71369447e-03 1.53569243e-04 0.00000000e+00\n",
      " 0.00000000e+00 2.29779380e-06 1.29059437e-04 2.10937555e-03\n",
      " 1.44427847e-02 5.94948679e-02 1.24456182e-01 2.03150302e-01\n",
      " 2.82244265e-01 3.39428633e-01 3.61441463e-01 3.73201638e-01\n",
      " 4.13510561e-01 4.79015738e-01 5.25484145e-01 5.51089644e-01\n",
      " 5.29901445e-01 4.84033346e-01 3.98011208e-01 3.07428747e-01\n",
      " 2.29727298e-01 1.59011200e-01 1.01290599e-01 5.55250607e-02\n",
      " 2.09635403e-02 3.30805802e-03 6.07383670e-04 2.29779380e-06\n",
      " 0.00000000e+00 3.52328461e-05 3.56541073e-04 2.86688097e-03\n",
      " 1.92647092e-02 6.81977794e-02 1.32639065e-01 2.02236533e-01\n",
      " 2.66284138e-01 3.10493231e-01 3.30831468e-01 3.53237182e-01\n",
      " 3.96811783e-01 4.52369422e-01 5.01086891e-01 5.13104260e-01\n",
      " 4.88676906e-01 4.44411755e-01 3.77638668e-01 3.06069881e-01\n",
      " 2.33306155e-01 1.60425469e-01 9.89686847e-02 5.22671677e-02\n",
      " 2.06602290e-02 4.22526104e-03 8.13419116e-04 4.21262212e-06\n",
      " 0.00000000e+00 2.91053966e-05 6.36489014e-04 4.48491052e-03\n",
      " 2.55284961e-02 7.75854066e-02 1.36625275e-01 1.97816685e-01\n",
      " 2.47107103e-01 2.77965337e-01 2.96399385e-01 3.19282353e-01\n",
      " 3.50133717e-01 4.02653247e-01 4.52548563e-01 4.65458453e-01\n",
      " 4.49672937e-01 4.15680856e-01 3.64384174e-01 3.02985251e-01\n",
      " 2.30487153e-01 1.56144321e-01 9.35650393e-02 4.72882167e-02\n",
      " 2.03730091e-02 5.83065255e-03 1.16766256e-03 4.28921630e-05\n",
      " 0.00000000e+00 6.89338322e-06 9.94562171e-04 7.52182771e-03\n",
      " 3.35301757e-02 8.56223106e-02 1.45067796e-01 1.99473783e-01\n",
      " 2.35507846e-01 2.61963904e-01 2.82924294e-01 2.99275845e-01\n",
      " 3.24255556e-01 3.79102319e-01 4.27750945e-01 4.45426702e-01\n",
      " 4.39175487e-01 4.13512558e-01 3.66264582e-01 2.98041195e-01\n",
      " 2.16834426e-01 1.43233776e-01 8.28910097e-02 4.05553095e-02\n",
      " 1.69791672e-02 4.69975406e-03 5.36534877e-04 1.08379281e-04\n",
      " 0.00000000e+00 0.00000000e+00 1.47863047e-03 1.05024530e-02\n",
      " 3.88499498e-02 9.34677348e-02 1.57761589e-01 2.12396592e-01\n",
      " 2.50571787e-01 2.80267268e-01 3.06436479e-01 3.22650909e-01\n",
      " 3.54604751e-01 4.07702595e-01 4.49304849e-01 4.61061954e-01\n",
      " 4.51730251e-01 4.17679965e-01 3.57743561e-01 2.75059015e-01\n",
      " 1.91341892e-01 1.19954430e-01 6.51554689e-02 3.06713358e-02\n",
      " 1.24111539e-02 3.04534379e-03 2.64246366e-04 5.66789349e-05\n",
      " 0.00000000e+00 1.49356611e-05 1.80798105e-03 1.13239149e-02\n",
      " 3.78412306e-02 8.95664990e-02 1.60410985e-01 2.24792436e-01\n",
      " 2.76505113e-01 3.20614636e-01 3.55537355e-01 3.83608669e-01\n",
      " 4.24673319e-01 4.70654905e-01 4.94765192e-01 4.90774363e-01\n",
      " 4.57127720e-01 3.98746967e-01 3.19976181e-01 2.32536376e-01\n",
      " 1.52743593e-01 8.96327496e-02 4.66409959e-02 2.18301974e-02\n",
      " 8.79289117e-03 1.87768089e-03 2.77267158e-04 1.91482868e-05\n",
      " 0.00000000e+00 2.75735292e-05 1.44454686e-03 8.61136615e-03\n",
      " 2.81575508e-02 7.28680342e-02 1.42569661e-01 2.17411548e-01\n",
      " 2.84816533e-01 3.49293470e-01 4.02283698e-01 4.48456973e-01\n",
      " 4.89529699e-01 5.18406332e-01 5.15267789e-01 4.79520887e-01\n",
      " 4.16718781e-01 3.33896667e-01 2.47254178e-01 1.69138685e-01\n",
      " 1.05075076e-01 5.93033880e-02 3.05147059e-02 1.32747395e-02\n",
      " 5.40058129e-03 1.18336384e-03 1.95695480e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 6.89721142e-04 4.46806056e-03\n",
      " 1.50172366e-02 4.30227481e-02 9.59244817e-02 1.68278575e-01\n",
      " 2.48389974e-01 3.26328903e-01 3.99626195e-01 4.50407475e-01\n",
      " 4.80903089e-01 4.85644221e-01 4.57765013e-01 4.01768148e-01\n",
      " 3.22133869e-01 2.39229485e-01 1.66479781e-01 1.05612762e-01\n",
      " 6.22487776e-02 3.48900855e-02 1.77856963e-02 7.40387524e-03\n",
      " 2.83203134e-03 7.15762726e-04 8.99969309e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 8.34865205e-05 1.21553300e-03\n",
      " 5.77895157e-03 1.76428445e-02 4.55882400e-02 9.32050496e-02\n",
      " 1.61846310e-01 2.38669991e-01 3.12052697e-01 3.65406603e-01\n",
      " 3.85710388e-01 3.74680609e-01 3.38445187e-01 2.77131677e-01\n",
      " 2.06985682e-01 1.43368244e-01 9.18692499e-02 5.69282286e-02\n",
      " 3.30288820e-02 1.80342402e-02 8.76416918e-03 3.63855646e-03\n",
      " 6.64828462e-04 6.77849384e-05 3.21691114e-05 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 4.98621317e-04\n",
      " 2.30277330e-03 6.36450620e-03 1.66011825e-02 3.54247056e-02\n",
      " 6.55170009e-02 1.07647046e-01 1.51787311e-01 1.81880772e-01\n",
      " 1.92358285e-01 1.88761488e-01 1.67838186e-01 1.32023245e-01\n",
      " 9.76650640e-02 6.70833588e-02 4.43386212e-02 2.78511792e-02\n",
      " 1.74919553e-02 9.28232633e-03 4.24862234e-03 1.78461999e-03\n",
      " 3.79519042e-04 1.34037991e-05 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.40839506e-05\n",
      " 5.13556937e-04 2.46017147e-03 6.41352683e-03 1.37603404e-02\n",
      " 2.69841459e-02 4.30097245e-02 5.83812110e-02 6.39866665e-02\n",
      " 6.54944107e-02 6.55058995e-02 5.88855632e-02 4.75118682e-02\n",
      " 3.88442092e-02 2.87913624e-02 1.97437946e-02 1.30062811e-02\n",
      " 8.11121147e-03 4.20726184e-03 1.75666343e-03 7.11933186e-04\n",
      " 1.27527572e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 1.45526928e-05\n",
      " 1.65824138e-04 7.04656937e-04 2.70641805e-03 5.82452444e-03\n",
      " 1.14096981e-02 1.67432539e-02 2.12630220e-02 2.22717579e-02\n",
      " 2.14824583e-02 2.16463711e-02 2.10447311e-02 1.60512403e-02\n",
      " 1.24433218e-02 9.48874373e-03 6.86351024e-03 4.50291065e-03\n",
      " 2.64667580e-03 1.34420977e-03 5.23513998e-04 1.37867624e-04\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 6.77849312e-05 1.59696734e-04 4.05177765e-04\n",
      " 5.83639659e-04 6.18489634e-04 1.12515315e-03 1.73866400e-03\n",
      " 2.49387301e-03 2.61565554e-03 2.74969381e-03 2.16490543e-03\n",
      " 1.54028763e-03 9.95710841e-04 7.60186929e-04 3.86795378e-04\n",
      " 2.17141554e-04 1.32123183e-04 1.29059437e-04 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\u001b[0m\n",
      "\u001b[34m<NDArray 784 @cpu(0)>}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] nvidia-smi: took 0.036 seconds to run.\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] nvidia-smi identified 0 GPUs.\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:31 INFO 139660246460224] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378091.4968083, \"EndTime\": 1716378091.4968626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"Meta\": \"init_train_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 10400.0, \"count\": 1, \"min\": 10400, \"max\": 10400}, \"Total Batches Seen\": {\"sum\": 52.0, \"count\": 1, \"min\": 52, \"max\": 52}, \"Max Records Seen Between Resets\": {\"sum\": 10200.0, \"count\": 1, \"min\": 10200, \"max\": 10200}, \"Max Batches Seen Between Resets\": {\"sum\": 51.0, \"count\": 1, \"min\": 51, \"max\": 51}, \"Reset Count\": {\"sum\": 2.0, \"count\": 1, \"min\": 2, \"max\": 2}, \"Number of Records Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}, \"Number of Batches Since Last Reset\": {\"sum\": 0.0, \"count\": 1, \"min\": 0, \"max\": 0}}}\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:35.904] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 3, \"duration\": 4407, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9050457, \"EndTime\": 1716378095.9051254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13601245830535888, \"count\": 1, \"min\": 0.13601245830535888, \"max\": 0.13601245830535888}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9051976, \"EndTime\": 1716378095.905209, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1339173860168457, \"count\": 1, \"min\": 0.1339173860168457, \"max\": 0.1339173860168457}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9052553, \"EndTime\": 1716378095.9052653, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13343331678390502, \"count\": 1, \"min\": 0.13343331678390502, \"max\": 0.13343331678390502}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905304, \"EndTime\": 1716378095.9053137, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13469792325973512, \"count\": 1, \"min\": 0.13469792325973512, \"max\": 0.13469792325973512}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9053473, \"EndTime\": 1716378095.905356, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1835616677302122, \"count\": 1, \"min\": 0.1835616677302122, \"max\": 0.1835616677302122}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905393, \"EndTime\": 1716378095.9054031, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1986246542159468, \"count\": 1, \"min\": 0.1986246542159468, \"max\": 0.1986246542159468}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9054375, \"EndTime\": 1716378095.905447, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.18718150935992597, \"count\": 1, \"min\": 0.18718150935992597, \"max\": 0.18718150935992597}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9054773, \"EndTime\": 1716378095.9054854, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.19651478447927162, \"count\": 1, \"min\": 0.19651478447927162, \"max\": 0.19651478447927162}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9055085, \"EndTime\": 1716378095.9055161, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13511297475814818, \"count\": 1, \"min\": 0.13511297475814818, \"max\": 0.13511297475814818}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9055352, \"EndTime\": 1716378095.9055405, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13200088909149169, \"count\": 1, \"min\": 0.13200088909149169, \"max\": 0.13200088909149169}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9055555, \"EndTime\": 1716378095.9055622, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13114209729194642, \"count\": 1, \"min\": 0.13114209729194642, \"max\": 0.13114209729194642}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905588, \"EndTime\": 1716378095.905596, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1316321087551117, \"count\": 1, \"min\": 0.1316321087551117, \"max\": 0.1316321087551117}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905625, \"EndTime\": 1716378095.9056327, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13802010006308554, \"count\": 1, \"min\": 0.13802010006308554, \"max\": 0.13802010006308554}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905664, \"EndTime\": 1716378095.9056726, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.15543329360984265, \"count\": 1, \"min\": 0.15543329360984265, \"max\": 0.15543329360984265}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9057076, \"EndTime\": 1716378095.9057164, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.14144959698319434, \"count\": 1, \"min\": 0.14144959698319434, \"max\": 0.14144959698319434}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9057498, \"EndTime\": 1716378095.9057558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.15132120890438558, \"count\": 1, \"min\": 0.15132120890438558, \"max\": 0.15132120890438558}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9057715, \"EndTime\": 1716378095.905776, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.15907261028289796, \"count\": 1, \"min\": 0.15907261028289796, \"max\": 0.15907261028289796}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9057908, \"EndTime\": 1716378095.9057968, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1544796887397766, \"count\": 1, \"min\": 0.1544796887397766, \"max\": 0.1544796887397766}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9058185, \"EndTime\": 1716378095.9058235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1556040065574646, \"count\": 1, \"min\": 0.1556040065574646, \"max\": 0.1556040065574646}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9058383, \"EndTime\": 1716378095.9058444, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.155760298538208, \"count\": 1, \"min\": 0.155760298538208, \"max\": 0.155760298538208}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9058764, \"EndTime\": 1716378095.9058843, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.15993022289276124, \"count\": 1, \"min\": 0.15993022289276124, \"max\": 0.15993022289276124}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.905915, \"EndTime\": 1716378095.9059238, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1627838395690918, \"count\": 1, \"min\": 0.1627838395690918, \"max\": 0.1627838395690918}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9059591, \"EndTime\": 1716378095.9059677, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.16384555492401123, \"count\": 1, \"min\": 0.16384555492401123, \"max\": 0.16384555492401123}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9060032, \"EndTime\": 1716378095.9060113, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.16884661577224733, \"count\": 1, \"min\": 0.16884661577224733, \"max\": 0.16884661577224733}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.906041, \"EndTime\": 1716378095.9060485, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.332652490234375, \"count\": 1, \"min\": 0.332652490234375, \"max\": 0.332652490234375}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9060788, \"EndTime\": 1716378095.9060874, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.33218759544372556, \"count\": 1, \"min\": 0.33218759544372556, \"max\": 0.33218759544372556}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.906116, \"EndTime\": 1716378095.9061244, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3338672378540039, \"count\": 1, \"min\": 0.3338672378540039, \"max\": 0.3338672378540039}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.906155, \"EndTime\": 1716378095.9061642, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3318760410308838, \"count\": 1, \"min\": 0.3318760410308838, \"max\": 0.3318760410308838}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9061947, \"EndTime\": 1716378095.9062035, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3189338005065918, \"count\": 1, \"min\": 0.3189338005065918, \"max\": 0.3189338005065918}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.906239, \"EndTime\": 1716378095.9062479, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.319676448135376, \"count\": 1, \"min\": 0.319676448135376, \"max\": 0.319676448135376}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9062765, \"EndTime\": 1716378095.9062817, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.31735560150146486, \"count\": 1, \"min\": 0.31735560150146486, \"max\": 0.31735560150146486}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9062977, \"EndTime\": 1716378095.9063046, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3182295166015625, \"count\": 1, \"min\": 0.3182295166015625, \"max\": 0.3182295166015625}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] #quality_metric: host=algo-1, epoch=0, train binary_classification_cross_entropy_objective <loss>=0.13601245830535888\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] #early_stopping_criteria_metric: host=algo-1, epoch=0, criteria=binary_classification_cross_entropy_objective, value=0.13114209729194642\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] Epoch 0: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] Saving model for epoch: 0\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] Saved checkpoint to \"/tmp/tmpu1us8juh/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] #progress_metric: host=algo-1, completed 20.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378091.4970765, \"EndTime\": 1716378095.9132638, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 0, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 60400.0, \"count\": 1, \"min\": 60400, \"max\": 60400}, \"Total Batches Seen\": {\"sum\": 302.0, \"count\": 1, \"min\": 302, \"max\": 302}, \"Max Records Seen Between Resets\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Max Batches Seen Between Resets\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Reset Count\": {\"sum\": 3.0, \"count\": 1, \"min\": 3, \"max\": 3}, \"Number of Records Since Last Reset\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Number of Batches Since Last Reset\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:35 INFO 139660246460224] #throughput_metric: host=algo-1, train throughput=11321.74949111156 records/second\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:40.780] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 5, \"duration\": 4866, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.780617, \"EndTime\": 1716378100.780671, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.039508256464004514, \"count\": 1, \"min\": 0.039508256464004514, \"max\": 0.039508256464004514}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7807257, \"EndTime\": 1716378100.7807384, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03718879582643509, \"count\": 1, \"min\": 0.03718879582643509, \"max\": 0.03718879582643509}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.780766, \"EndTime\": 1716378100.7807744, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.0394974626326561, \"count\": 1, \"min\": 0.0394974626326561, \"max\": 0.0394974626326561}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.780803, \"EndTime\": 1716378100.780812, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03694312445163727, \"count\": 1, \"min\": 0.03694312445163727, \"max\": 0.03694312445163727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.780854, \"EndTime\": 1716378100.7808626, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.09658778093048778, \"count\": 1, \"min\": 0.09658778093048778, \"max\": 0.09658778093048778}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7808893, \"EndTime\": 1716378100.7808979, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12176442123818823, \"count\": 1, \"min\": 0.12176442123818823, \"max\": 0.12176442123818823}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7809215, \"EndTime\": 1716378100.7809303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.0944225756936724, \"count\": 1, \"min\": 0.0944225756936724, \"max\": 0.0944225756936724}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.780953, \"EndTime\": 1716378100.7809615, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12462514723513742, \"count\": 1, \"min\": 0.12462514723513742, \"max\": 0.12462514723513742}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7809846, \"EndTime\": 1716378100.7809918, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03977077572345734, \"count\": 1, \"min\": 0.03977077572345734, \"max\": 0.03977077572345734}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7810187, \"EndTime\": 1716378100.781027, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03887222484111786, \"count\": 1, \"min\": 0.03887222484111786, \"max\": 0.03887222484111786}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.78105, \"EndTime\": 1716378100.7810583, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.04006563522338867, \"count\": 1, \"min\": 0.04006563522338867, \"max\": 0.04006563522338867}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7810812, \"EndTime\": 1716378100.781089, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03824115242958069, \"count\": 1, \"min\": 0.03824115242958069, \"max\": 0.03824115242958069}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7811124, \"EndTime\": 1716378100.7811196, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.08932492526888848, \"count\": 1, \"min\": 0.08932492526888848, \"max\": 0.08932492526888848}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7811468, \"EndTime\": 1716378100.7811558, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.11819746522367, \"count\": 1, \"min\": 0.11819746522367, \"max\": 0.11819746522367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7811787, \"EndTime\": 1716378100.7811868, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.09912617056369781, \"count\": 1, \"min\": 0.09912617056369781, \"max\": 0.09912617056369781}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7812092, \"EndTime\": 1716378100.7812176, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12645209238052368, \"count\": 1, \"min\": 0.12645209238052368, \"max\": 0.12645209238052368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.781241, \"EndTime\": 1716378100.7812479, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10804369569778442, \"count\": 1, \"min\": 0.10804369569778442, \"max\": 0.10804369569778442}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7812743, \"EndTime\": 1716378100.7812827, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10849044315338134, \"count\": 1, \"min\": 0.10849044315338134, \"max\": 0.10849044315338134}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7813056, \"EndTime\": 1716378100.7813141, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10815295370101928, \"count\": 1, \"min\": 0.10815295370101928, \"max\": 0.10815295370101928}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7813365, \"EndTime\": 1716378100.7813451, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10850780220031739, \"count\": 1, \"min\": 0.10850780220031739, \"max\": 0.10850780220031739}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7813675, \"EndTime\": 1716378100.781375, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13319448875427245, \"count\": 1, \"min\": 0.13319448875427245, \"max\": 0.13319448875427245}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7814016, \"EndTime\": 1716378100.78141, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.15092348148345947, \"count\": 1, \"min\": 0.15092348148345947, \"max\": 0.15092348148345947}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7814326, \"EndTime\": 1716378100.7814407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13128709436416627, \"count\": 1, \"min\": 0.13128709436416627, \"max\": 0.13128709436416627}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7814636, \"EndTime\": 1716378100.7814717, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.14752464656829833, \"count\": 1, \"min\": 0.14752464656829833, \"max\": 0.14752464656829833}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.781495, \"EndTime\": 1716378100.7815025, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30644669357299803, \"count\": 1, \"min\": 0.30644669357299803, \"max\": 0.30644669357299803}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7815292, \"EndTime\": 1716378100.7815373, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064574040222168, \"count\": 1, \"min\": 0.3064574040222168, \"max\": 0.3064574040222168}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7815602, \"EndTime\": 1716378100.7815683, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30640142738342285, \"count\": 1, \"min\": 0.30640142738342285, \"max\": 0.30640142738342285}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.781591, \"EndTime\": 1716378100.7815995, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064325436401367, \"count\": 1, \"min\": 0.3064325436401367, \"max\": 0.3064325436401367}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7816224, \"EndTime\": 1716378100.7816293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3083432795715332, \"count\": 1, \"min\": 0.3083432795715332, \"max\": 0.3083432795715332}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7816558, \"EndTime\": 1716378100.7816644, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3094398107910156, \"count\": 1, \"min\": 0.3094398107910156, \"max\": 0.3094398107910156}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7816865, \"EndTime\": 1716378100.7816947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.31002676597595213, \"count\": 1, \"min\": 0.31002676597595213, \"max\": 0.31002676597595213}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7817173, \"EndTime\": 1716378100.7817254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30973311164855954, \"count\": 1, \"min\": 0.30973311164855954, \"max\": 0.30973311164855954}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] #quality_metric: host=algo-1, epoch=1, train binary_classification_cross_entropy_objective <loss>=0.039508256464004514\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] #early_stopping_criteria_metric: host=algo-1, epoch=1, criteria=binary_classification_cross_entropy_objective, value=0.03694312445163727\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] Epoch 1: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] Saving model for epoch: 1\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] Saved checkpoint to \"/tmp/tmpnkyn4zs2/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] #progress_metric: host=algo-1, completed 40.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378095.9138951, \"EndTime\": 1716378100.789954, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 1, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 110400.0, \"count\": 1, \"min\": 110400, \"max\": 110400}, \"Total Batches Seen\": {\"sum\": 552.0, \"count\": 1, \"min\": 552, \"max\": 552}, \"Max Records Seen Between Resets\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Max Batches Seen Between Resets\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Reset Count\": {\"sum\": 4.0, \"count\": 1, \"min\": 4, \"max\": 4}, \"Number of Records Since Last Reset\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Number of Batches Since Last Reset\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:40 INFO 139660246460224] #throughput_metric: host=algo-1, train throughput=10253.89382586268 records/second\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:45.261] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 7, \"duration\": 4467, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2619486, \"EndTime\": 1716378105.262008, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03211880851268768, \"count\": 1, \"min\": 0.03211880851268768, \"max\": 0.03211880851268768}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2620654, \"EndTime\": 1716378105.2620778, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03084811170101166, \"count\": 1, \"min\": 0.03084811170101166, \"max\": 0.03084811170101166}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2621105, \"EndTime\": 1716378105.2621188, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.032101217167377474, \"count\": 1, \"min\": 0.032101217167377474, \"max\": 0.032101217167377474}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2621453, \"EndTime\": 1716378105.2621527, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03072658412218094, \"count\": 1, \"min\": 0.03072658412218094, \"max\": 0.03072658412218094}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2621787, \"EndTime\": 1716378105.2621865, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.08229743313185056, \"count\": 1, \"min\": 0.08229743313185056, \"max\": 0.08229743313185056}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262221, \"EndTime\": 1716378105.2622292, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12362301726697768, \"count\": 1, \"min\": 0.12362301726697768, \"max\": 0.12362301726697768}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2622626, \"EndTime\": 1716378105.2622695, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.08398049739360912, \"count\": 1, \"min\": 0.08398049739360912, \"max\": 0.08398049739360912}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2622924, \"EndTime\": 1716378105.2622993, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.11545073601033015, \"count\": 1, \"min\": 0.11545073601033015, \"max\": 0.11545073601033015}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262327, \"EndTime\": 1716378105.2623358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03403089747428894, \"count\": 1, \"min\": 0.03403089747428894, \"max\": 0.03403089747428894}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2623613, \"EndTime\": 1716378105.2623684, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03323359547615051, \"count\": 1, \"min\": 0.03323359547615051, \"max\": 0.03323359547615051}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2623913, \"EndTime\": 1716378105.262396, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03396252694129944, \"count\": 1, \"min\": 0.03396252694129944, \"max\": 0.03396252694129944}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2624164, \"EndTime\": 1716378105.2624235, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03334729847431183, \"count\": 1, \"min\": 0.03334729847431183, \"max\": 0.03334729847431183}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262455, \"EndTime\": 1716378105.2624636, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.07130920598268509, \"count\": 1, \"min\": 0.07130920598268509, \"max\": 0.07130920598268509}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2624986, \"EndTime\": 1716378105.262506, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12257918819189072, \"count\": 1, \"min\": 0.12257918819189072, \"max\": 0.12257918819189072}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2625365, \"EndTime\": 1716378105.2625442, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.07550911728024483, \"count\": 1, \"min\": 0.07550911728024483, \"max\": 0.07550911728024483}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2625692, \"EndTime\": 1716378105.2625768, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12857357102870942, \"count\": 1, \"min\": 0.12857357102870942, \"max\": 0.12857357102870942}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2626073, \"EndTime\": 1716378105.2626162, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10765367704391479, \"count\": 1, \"min\": 0.10765367704391479, \"max\": 0.10765367704391479}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262637, \"EndTime\": 1716378105.262644, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10847010330200195, \"count\": 1, \"min\": 0.10847010330200195, \"max\": 0.10847010330200195}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2626674, \"EndTime\": 1716378105.2626746, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10773727561950684, \"count\": 1, \"min\": 0.10773727561950684, \"max\": 0.10773727561950684}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2627008, \"EndTime\": 1716378105.2627087, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1084934241104126, \"count\": 1, \"min\": 0.1084934241104126, \"max\": 0.1084934241104126}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262737, \"EndTime\": 1716378105.2627459, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1260256102180481, \"count\": 1, \"min\": 0.1260256102180481, \"max\": 0.1260256102180481}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2627783, \"EndTime\": 1716378105.2627838, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.150543741607666, \"count\": 1, \"min\": 0.150543741607666, \"max\": 0.150543741607666}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.262808, \"EndTime\": 1716378105.2628148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1260727473640442, \"count\": 1, \"min\": 0.1260727473640442, \"max\": 0.1260727473640442}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2628443, \"EndTime\": 1716378105.2628524, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.14943598592758178, \"count\": 1, \"min\": 0.14943598592758178, \"max\": 0.14943598592758178}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2628822, \"EndTime\": 1716378105.2628906, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064460682678223, \"count\": 1, \"min\": 0.3064460682678223, \"max\": 0.3064460682678223}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2629175, \"EndTime\": 1716378105.2629256, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064851319122314, \"count\": 1, \"min\": 0.3064851319122314, \"max\": 0.3064851319122314}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.26295, \"EndTime\": 1716378105.2629576, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30640371543884276, \"count\": 1, \"min\": 0.30640371543884276, \"max\": 0.30640371543884276}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2629848, \"EndTime\": 1716378105.2629926, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064663356781006, \"count\": 1, \"min\": 0.3064663356781006, \"max\": 0.3064663356781006}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.263019, \"EndTime\": 1716378105.2630267, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3088462431335449, \"count\": 1, \"min\": 0.3088462431335449, \"max\": 0.3088462431335449}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2630513, \"EndTime\": 1716378105.263056, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3095548558807373, \"count\": 1, \"min\": 0.3095548558807373, \"max\": 0.3095548558807373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2630768, \"EndTime\": 1716378105.2630842, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30848528594970703, \"count\": 1, \"min\": 0.30848528594970703, \"max\": 0.30848528594970703}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.2631083, \"EndTime\": 1716378105.263116, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.309613507232666, \"count\": 1, \"min\": 0.309613507232666, \"max\": 0.309613507232666}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] #quality_metric: host=algo-1, epoch=2, train binary_classification_cross_entropy_objective <loss>=0.03211880851268768\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] #early_stopping_criteria_metric: host=algo-1, epoch=2, criteria=binary_classification_cross_entropy_objective, value=0.03072658412218094\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] Epoch 2: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] Saving model for epoch: 2\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] Saved checkpoint to \"/tmp/tmpczhbreu4/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] #progress_metric: host=algo-1, completed 60.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378100.7942505, \"EndTime\": 1716378105.2702332, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 2, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 160400.0, \"count\": 1, \"min\": 160400, \"max\": 160400}, \"Total Batches Seen\": {\"sum\": 802.0, \"count\": 1, \"min\": 802, \"max\": 802}, \"Max Records Seen Between Resets\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Max Batches Seen Between Resets\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Reset Count\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"Number of Records Since Last Reset\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Number of Batches Since Last Reset\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:45 INFO 139660246460224] #throughput_metric: host=algo-1, train throughput=11170.509435786344 records/second\u001b[0m\n",
      "\n",
      "2024-05-22 11:41:59 Uploading - Uploading generated training model\u001b[34m[2024-05-22 11:41:49.687] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 9, \"duration\": 4416, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6871824, \"EndTime\": 1716378109.687241, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.02922982458472252, \"count\": 1, \"min\": 0.02922982458472252, \"max\": 0.02922982458472252}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6873052, \"EndTime\": 1716378109.6873178, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.02834384692788124, \"count\": 1, \"min\": 0.02834384692788124, \"max\": 0.02834384692788124}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6873515, \"EndTime\": 1716378109.687361, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.02905749149799347, \"count\": 1, \"min\": 0.02905749149799347, \"max\": 0.02905749149799347}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6873925, \"EndTime\": 1716378109.6873987, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.028287336407899856, \"count\": 1, \"min\": 0.028287336407899856, \"max\": 0.028287336407899856}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6874206, \"EndTime\": 1716378109.6874278, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.06860432717291522, \"count\": 1, \"min\": 0.06860432717291522, \"max\": 0.06860432717291522}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6874552, \"EndTime\": 1716378109.6874638, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.13110415196614286, \"count\": 1, \"min\": 0.13110415196614286, \"max\": 0.13110415196614286}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.687495, \"EndTime\": 1716378109.6875036, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.06994388268559938, \"count\": 1, \"min\": 0.06994388268559938, \"max\": 0.06994388268559938}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.687538, \"EndTime\": 1716378109.687546, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12975461052617934, \"count\": 1, \"min\": 0.12975461052617934, \"max\": 0.12975461052617934}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6875799, \"EndTime\": 1716378109.687589, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03190428654193878, \"count\": 1, \"min\": 0.03190428654193878, \"max\": 0.03190428654193878}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6876113, \"EndTime\": 1716378109.6876166, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03172267335176468, \"count\": 1, \"min\": 0.03172267335176468, \"max\": 0.03172267335176468}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6876442, \"EndTime\": 1716378109.6876519, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.031855016412734985, \"count\": 1, \"min\": 0.031855016412734985, \"max\": 0.031855016412734985}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6876836, \"EndTime\": 1716378109.687691, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03193851977825165, \"count\": 1, \"min\": 0.03193851977825165, \"max\": 0.03193851977825165}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6877286, \"EndTime\": 1716378109.6877358, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.063772580601573, \"count\": 1, \"min\": 0.063772580601573, \"max\": 0.063772580601573}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.687766, \"EndTime\": 1716378109.687775, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1092619345484674, \"count\": 1, \"min\": 0.1092619345484674, \"max\": 0.1092619345484674}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6878057, \"EndTime\": 1716378109.687813, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.060853169530034064, \"count\": 1, \"min\": 0.060853169530034064, \"max\": 0.060853169530034064}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6878426, \"EndTime\": 1716378109.6878507, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1274410348433256, \"count\": 1, \"min\": 0.1274410348433256, \"max\": 0.1274410348433256}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6878858, \"EndTime\": 1716378109.687895, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10732564205169677, \"count\": 1, \"min\": 0.10732564205169677, \"max\": 0.10732564205169677}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6879306, \"EndTime\": 1716378109.6879401, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10847812314987183, \"count\": 1, \"min\": 0.10847812314987183, \"max\": 0.10847812314987183}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6879756, \"EndTime\": 1716378109.687985, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1073713782119751, \"count\": 1, \"min\": 0.1073713782119751, \"max\": 0.1073713782119751}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6880202, \"EndTime\": 1716378109.6880293, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10850099576950073, \"count\": 1, \"min\": 0.10850099576950073, \"max\": 0.10850099576950073}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6880596, \"EndTime\": 1716378109.688068, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12178947151184082, \"count\": 1, \"min\": 0.12178947151184082, \"max\": 0.12178947151184082}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6881006, \"EndTime\": 1716378109.6881082, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.14759048404693603, \"count\": 1, \"min\": 0.14759048404693603, \"max\": 0.14759048404693603}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6881404, \"EndTime\": 1716378109.6881487, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12173141838073731, \"count\": 1, \"min\": 0.12173141838073731, \"max\": 0.12173141838073731}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.688179, \"EndTime\": 1716378109.688187, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1465599387359619, \"count\": 1, \"min\": 0.1465599387359619, \"max\": 0.1465599387359619}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.688223, \"EndTime\": 1716378109.6882317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064276396942139, \"count\": 1, \"min\": 0.3064276396942139, \"max\": 0.3064276396942139}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6882677, \"EndTime\": 1716378109.6882765, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3065139965057373, \"count\": 1, \"min\": 0.3065139965057373, \"max\": 0.3065139965057373}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6883097, \"EndTime\": 1716378109.688318, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.306405343170166, \"count\": 1, \"min\": 0.306405343170166, \"max\": 0.306405343170166}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6883516, \"EndTime\": 1716378109.6883605, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3064989499664307, \"count\": 1, \"min\": 0.3064989499664307, \"max\": 0.3064989499664307}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6883914, \"EndTime\": 1716378109.6883996, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30799703231811526, \"count\": 1, \"min\": 0.30799703231811526, \"max\": 0.30799703231811526}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6884234, \"EndTime\": 1716378109.6884303, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3101338363647461, \"count\": 1, \"min\": 0.3101338363647461, \"max\": 0.3101338363647461}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.688454, \"EndTime\": 1716378109.688462, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3084996887207031, \"count\": 1, \"min\": 0.3084996887207031, \"max\": 0.3084996887207031}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.6884944, \"EndTime\": 1716378109.688502, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3096573703765869, \"count\": 1, \"min\": 0.3096573703765869, \"max\": 0.3096573703765869}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] #quality_metric: host=algo-1, epoch=3, train binary_classification_cross_entropy_objective <loss>=0.02922982458472252\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] #early_stopping_criteria_metric: host=algo-1, epoch=3, criteria=binary_classification_cross_entropy_objective, value=0.028287336407899856\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] Epoch 3: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] Saving model for epoch: 3\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] Saved checkpoint to \"/tmp/tmp37iv7pox/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] #progress_metric: host=algo-1, completed 80.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378105.270836, \"EndTime\": 1716378109.6951022, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 3, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 210400.0, \"count\": 1, \"min\": 210400, \"max\": 210400}, \"Total Batches Seen\": {\"sum\": 1052.0, \"count\": 1, \"min\": 1052, \"max\": 1052}, \"Max Records Seen Between Resets\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Max Batches Seen Between Resets\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Reset Count\": {\"sum\": 6.0, \"count\": 1, \"min\": 6, \"max\": 6}, \"Number of Records Since Last Reset\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Number of Batches Since Last Reset\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:49 INFO 139660246460224] #throughput_metric: host=algo-1, train throughput=11301.031072942464 records/second\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:54.119] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 11, \"duration\": 4423, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1191928, \"EndTime\": 1716378114.119254, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 0}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.027582718749046324, \"count\": 1, \"min\": 0.027582718749046324, \"max\": 0.027582718749046324}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1193213, \"EndTime\": 1716378114.1193347, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 1}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.02703313249707222, \"count\": 1, \"min\": 0.02703313249707222, \"max\": 0.02703313249707222}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1193693, \"EndTime\": 1716378114.1193767, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 2}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.027466045610904693, \"count\": 1, \"min\": 0.027466045610904693, \"max\": 0.027466045610904693}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1194012, \"EndTime\": 1716378114.119407, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 3}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.027028971717357634, \"count\": 1, \"min\": 0.027028971717357634, \"max\": 0.027028971717357634}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1194253, \"EndTime\": 1716378114.119432, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 4}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.05773518460427993, \"count\": 1, \"min\": 0.05773518460427993, \"max\": 0.05773518460427993}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1194596, \"EndTime\": 1716378114.1194668, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 5}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12445192683643727, \"count\": 1, \"min\": 0.12445192683643727, \"max\": 0.12445192683643727}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1194928, \"EndTime\": 1716378114.1195006, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 6}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.06048622105163726, \"count\": 1, \"min\": 0.06048622105163726, \"max\": 0.06048622105163726}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1195188, \"EndTime\": 1716378114.1195257, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 7}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.11282218320532336, \"count\": 1, \"min\": 0.11282218320532336, \"max\": 0.11282218320532336}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1195443, \"EndTime\": 1716378114.1195493, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 8}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03077622759103775, \"count\": 1, \"min\": 0.03077622759103775, \"max\": 0.03077622759103775}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1195638, \"EndTime\": 1716378114.119568, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 9}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.031141992979049682, \"count\": 1, \"min\": 0.031141992979049682, \"max\": 0.031141992979049682}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1195889, \"EndTime\": 1716378114.1195948, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 10}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.030749254689216615, \"count\": 1, \"min\": 0.030749254689216615, \"max\": 0.030749254689216615}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1196246, \"EndTime\": 1716378114.1196322, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 11}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.03118614330291748, \"count\": 1, \"min\": 0.03118614330291748, \"max\": 0.03118614330291748}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.119659, \"EndTime\": 1716378114.1196659, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 12}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.05425437896847725, \"count\": 1, \"min\": 0.05425437896847725, \"max\": 0.05425437896847725}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1196942, \"EndTime\": 1716378114.1197014, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 13}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.12062253970980644, \"count\": 1, \"min\": 0.12062253970980644, \"max\": 0.12062253970980644}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1197312, \"EndTime\": 1716378114.1197402, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 14}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.054180973658561705, \"count\": 1, \"min\": 0.054180973658561705, \"max\": 0.054180973658561705}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1197696, \"EndTime\": 1716378114.1197774, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 15}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1016212238367647, \"count\": 1, \"min\": 0.1016212238367647, \"max\": 0.1016212238367647}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1198123, \"EndTime\": 1716378114.1198204, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 16}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10706559881210327, \"count\": 1, \"min\": 0.10706559881210327, \"max\": 0.10706559881210327}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1198494, \"EndTime\": 1716378114.1198575, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 17}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.1084690834236145, \"count\": 1, \"min\": 0.1084690834236145, \"max\": 0.1084690834236145}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1198864, \"EndTime\": 1716378114.1198947, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 18}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10708488094329834, \"count\": 1, \"min\": 0.10708488094329834, \"max\": 0.10708488094329834}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.119923, \"EndTime\": 1716378114.1199317, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 19}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.10849139308929444, \"count\": 1, \"min\": 0.10849139308929444, \"max\": 0.10849139308929444}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1199574, \"EndTime\": 1716378114.1199658, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 20}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.11991187744140624, \"count\": 1, \"min\": 0.11991187744140624, \"max\": 0.11991187744140624}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1200004, \"EndTime\": 1716378114.1200082, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 21}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.14913959238052368, \"count\": 1, \"min\": 0.14913959238052368, \"max\": 0.14913959238052368}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1200414, \"EndTime\": 1716378114.12005, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 22}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.11951114469528198, \"count\": 1, \"min\": 0.11951114469528198, \"max\": 0.11951114469528198}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1200783, \"EndTime\": 1716378114.1200864, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 23}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.146779278049469, \"count\": 1, \"min\": 0.146779278049469, \"max\": 0.146779278049469}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1201117, \"EndTime\": 1716378114.1201203, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 24}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30641409408569337, \"count\": 1, \"min\": 0.30641409408569337, \"max\": 0.30641409408569337}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1201465, \"EndTime\": 1716378114.1201544, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 25}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3065548038482666, \"count\": 1, \"min\": 0.3065548038482666, \"max\": 0.3065548038482666}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1201859, \"EndTime\": 1716378114.120194, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 26}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3063970802307129, \"count\": 1, \"min\": 0.3063970802307129, \"max\": 0.3063970802307129}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.120226, \"EndTime\": 1716378114.1202335, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 27}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.306529888381958, \"count\": 1, \"min\": 0.306529888381958, \"max\": 0.306529888381958}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1202612, \"EndTime\": 1716378114.1202698, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 28}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3073026959228516, \"count\": 1, \"min\": 0.3073026959228516, \"max\": 0.3073026959228516}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.120306, \"EndTime\": 1716378114.1203148, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 29}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3098162889099121, \"count\": 1, \"min\": 0.3098162889099121, \"max\": 0.3098162889099121}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.1203494, \"EndTime\": 1716378114.1203594, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 30}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.30734090850830076, \"count\": 1, \"min\": 0.30734090850830076, \"max\": 0.30734090850830076}}}\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378114.120388, \"EndTime\": 1716378114.1203976, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"model\": 31}, \"Metrics\": {\"train_binary_classification_cross_entropy_objective\": {\"sum\": 0.3105081169891357, \"count\": 1, \"min\": 0.3105081169891357, \"max\": 0.3105081169891357}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] #quality_metric: host=algo-1, epoch=4, train binary_classification_cross_entropy_objective <loss>=0.027582718749046324\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] #early_stopping_criteria_metric: host=algo-1, epoch=4, criteria=binary_classification_cross_entropy_objective, value=0.027028971717357634\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] Epoch 4: Loss improved. Updating best model\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] Saving model for epoch: 4\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] Saved checkpoint to \"/tmp/tmp89gufc_v/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] #progress_metric: host=algo-1, completed 100.0 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378109.695939, \"EndTime\": 1716378114.1282742, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\", \"epoch\": 4, \"Meta\": \"training_data_iter\"}, \"Metrics\": {\"Total Records Seen\": {\"sum\": 260400.0, \"count\": 1, \"min\": 260400, \"max\": 260400}, \"Total Batches Seen\": {\"sum\": 1302.0, \"count\": 1, \"min\": 1302, \"max\": 1302}, \"Max Records Seen Between Resets\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Max Batches Seen Between Resets\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}, \"Reset Count\": {\"sum\": 7.0, \"count\": 1, \"min\": 7, \"max\": 7}, \"Number of Records Since Last Reset\": {\"sum\": 50000.0, \"count\": 1, \"min\": 50000, \"max\": 50000}, \"Number of Batches Since Last Reset\": {\"sum\": 250.0, \"count\": 1, \"min\": 250, \"max\": 250}}}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 INFO 139660246460224] #throughput_metric: host=algo-1, train throughput=11280.432638052913 records/second\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 WARNING 139660246460224] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:54 WARNING 139660246460224] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:54.132] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 13, \"duration\": 3, \"num_examples\": 1, \"num_bytes\": 636800}\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:54.546] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 16, \"duration\": 411, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m[2024-05-22 11:41:55.095] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 18, \"duration\": 526, \"num_examples\": 250, \"num_bytes\": 159200000}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('binary_classification_cross_entropy_objective', 0.024695202825665473)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('binary_classification_accuracy', 0.99256)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('binary_f_1.000', 0.9619865113427345)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('precision', 0.9697156983930779)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('recall', 0.9543795620437956)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('roc_auc_score', 0.9977713005870699)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('binary_balanced_accuracy', 0.5001109434632112)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #train_score (algo-1) : ('binary_log_loss', 0.6618225598251865)\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train binary_classification_cross_entropy_objective <loss>=0.024695202825665473\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train binary_classification_accuracy <score>=0.99256\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train binary_f_1.000 <score>=0.9619865113427345\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train precision <score>=0.9697156983930779\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train recall <score>=0.9543795620437956\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train roc_auc_score <score>=0.9977713005870699\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train binary_balanced_accuracy <score>=0.5001109434632112\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] #quality_metric: host=algo-1, train binary_log_loss <score>=0.6618225598251865\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] Best model found for hyperparameters: {\"optimizer\": \"adam\", \"learning_rate\": 0.005, \"wd\": 0.0001, \"l1\": 0.0, \"lr_scheduler_step\": 100, \"lr_scheduler_factor\": 0.99, \"lr_scheduler_minimum_lr\": 0.0001}\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] Saved checkpoint to \"/tmp/tmp__znsce1/mx-mod-0000.params\"\u001b[0m\n",
      "\u001b[34m[05/22/2024 11:41:55 INFO 139660246460224] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"StartTime\": 1716378091.0933542, \"EndTime\": 1716378115.1581452, \"Dimensions\": {\"Algorithm\": \"Linear Learner\", \"Host\": \"algo-1\", \"Operation\": \"training\"}, \"Metrics\": {\"initialize.time\": {\"sum\": 393.3253288269043, \"count\": 1, \"min\": 393.3253288269043, \"max\": 393.3253288269043}, \"epochs\": {\"sum\": 5.0, \"count\": 1, \"min\": 5, \"max\": 5}, \"check_early_stopping.time\": {\"sum\": 3.249645233154297, \"count\": 5, \"min\": 0.6177425384521484, \"max\": 0.6694793701171875}, \"update.time\": {\"sum\": 22610.006093978882, \"count\": 5, \"min\": 4413.9604568481445, \"max\": 4872.915029525757}, \"finalize.time\": {\"sum\": 1025.3872871398926, \"count\": 1, \"min\": 1025.3872871398926, \"max\": 1025.3872871398926}, \"setuptime\": {\"sum\": 1.7547607421875, \"count\": 1, \"min\": 1.7547607421875, \"max\": 1.7547607421875}, \"totaltime\": {\"sum\": 24153.321743011475, \"count\": 1, \"min\": 24153.321743011475, \"max\": 24153.321743011475}}}\u001b[0m\n",
      "\n",
      "2024-05-22 11:42:12 Completed - Training job completed\n",
      "Training seconds: 179\n",
      "Billable seconds: 179\n"
     ]
    }
   ],
   "source": [
    "linear_manual = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c4.xlarge\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "linear_manual.set_hyperparameters(feature_dim=784, predictor_type=\"binary_classifier\", mini_batch_size=200, epochs=5)\n",
    "\n",
    "linear_manual.fit({\"train\": s3_train_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Automatic Model Tuning ([HPO](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html)) <a id='AMT'></a>\n",
    "***\n",
    "As mentioned above, instead of manually configuring our hyper parameter values and training with SageMaker Training, we'll use Amazon SageMaker Automatic Model Tuning.\n",
    "        \n",
    "The code sample below shows you how to use the HyperParameterTuner. For recommended default hyparameter ranges, check the [Amazon SageMaker Linear Learner HPs documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html).\n",
    "\n",
    "The tuning job will take 8 to 10 minutes to complete.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning job name: DEMO-ll-mni-2024-05-22-12-14-42\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "job_name = \"DEMO-ll-mni-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Tuning job name:\", job_name)\n",
    "\n",
    "# Linear Learner tunable hyperparameters can be found here https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner-tuning.html\n",
    "hyperparameter_ranges = {\n",
    "    \"wd\": ContinuousParameter(1e-7, 1, scaling_type=\"Auto\"),\n",
    "    \"learning_rate\": ContinuousParameter(1e-5, 1, scaling_type=\"Auto\"),\n",
    "    \"mini_batch_size\": IntegerParameter(100, 2000, scaling_type=\"Auto\"),\n",
    "}\n",
    "\n",
    "# Increase the total number of training jobs run by AMT, for increased accuracy (and training time).\n",
    "max_jobs = 6\n",
    "# Change parallel training jobs run by AMT to reduce total training time, constrained by your account limits.\n",
    "# if max_jobs=max_parallel_jobs then Bayesian search turns to Random.\n",
    "max_parallel_jobs = 2\n",
    "\n",
    "hp_tuner = HyperparameterTuner(\n",
    "    linear_manual,\n",
    "    \"validation:binary_f_beta\",\n",
    "    hyperparameter_ranges,\n",
    "    max_jobs=max_jobs,\n",
    "    max_parallel_jobs=max_parallel_jobs,\n",
    "    objective_type=\"Maximize\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: DEMO-ll-mni-2024-05-22-12-14-42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................................................................!\n"
     ]
    }
   ],
   "source": [
    "# Launch a SageMaker Tuning job to search for the best hyperparameters\n",
    "hp_tuner.fit(inputs={\"train\": s3_train_data, \"validation\": s3_validation_data}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hosting for the model\n",
    "Now that we've trained our model, we can deploy it behind an Amazon SageMaker real-time hosted endpoint.  This will allow out to make predictions (or inference) from the model dyanamically.\n",
    "\n",
    "_Note, Amazon SageMaker allows you the flexibility of importing models trained elsewhere, as well as the choice of not importing models if the target of model creation is AWS Lambda, AWS Greengrass, Amazon Redshift, Amazon Athena, or other deployment target._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2024-05-22 12:20:56 Starting - Found matching resource for reuse\n",
      "2024-05-22 12:20:56 Downloading - Downloading the training image\n",
      "2024-05-22 12:20:56 Training - Training image download completed. Training in progress.\n",
      "2024-05-22 12:20:56 Uploading - Uploading generated training model\n",
      "2024-05-22 12:20:56 Completed - Resource released due to keep alive period expiry"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: DEMO-ll-mni-2024-05-22-12-35-01-018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating endpoint-config with name DEMO-ll-mni-2024-05-22-12-14-42-006-06dabeeb\n",
      "INFO:sagemaker:Creating endpoint with name DEMO-ll-mni-2024-05-22-12-14-42-006-06dabeeb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "if deploy_amt_model:\n",
    "    linear_predictor = hp_tuner.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "else:\n",
    "    linear_predictor = linear.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate the model for use\n",
    "Finally, we can now validate the model for use.  We can pass HTTP POST requests to the endpoint to get back predictions.  To make this easier, we'll again use the Amazon SageMaker Python SDK and specify how to serialize requests and deserialize responses that are specific to the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "\n",
    "linear_predictor.serializer = CSVSerializer()\n",
    "linear_predictor.deserializer = JSONDeserializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try getting a prediction for a single record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img):\n",
    "    plt.imshow(img.reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_set[0][31])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 8.67609273313974e-09, 'predicted_label': 0}]}\n"
     ]
    }
   ],
   "source": [
    "# result = linear_predictor.predict(train_set[0][30:31], initial_args={\"ContentType\": \"text/csv\"})\n",
    "result = linear_predictor.predict(train_set[0][31], initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, a single prediction works.  We see that for one record our endpoint returned some JSON which contains `predictions`, including the `score` and `predicted_label`.  In this case, `score` will be a continuous value between [0, 1] representing the probability we think the digit is a 0 or not.  `predicted_label` will take a value of either `0` or `1` where (somewhat counterintuitively) `1` denotes that we predict the image is a 0, while `0` denotes that we are predicting the image is not of a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about predicting labels == 1 or when the number is actually zero?\n",
    "\n",
    "Let's grab a few indexes where the number is zero and run inference on those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, 21, 34])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(train_set[1] == 0)[0][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(train_set[0][21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'score': 0.9999938011169434, 'predicted_label': 1}]}\n"
     ]
    }
   ],
   "source": [
    "result = linear_predictor.predict(train_set[0][21], initial_args={\"ContentType\": \"text/csv\"})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also seems to work with a very high confidence.\n",
    "\n",
    "Let's do a whole batch of images and evaluate our predictive accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions = []\n",
    "for array in np.array_split(test_set[0], 100):\n",
    "    result = linear_predictor.predict(array)\n",
    "    predictions += [r[\"predicted_label\"] for r in result[\"predictions\"]]\n",
    "\n",
    "predictions = np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>predictions</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actuals</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8979</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "predictions     0    1\n",
       "actuals               \n",
       "0            8979   41\n",
       "1              47  933"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.crosstab(\n",
    "    np.where(test_set[1] == 0, 1, 0), predictions, rownames=[\"actuals\"], colnames=[\"predictions\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "If you're ready to be done with this notebook, please run the delete_endpoint line in the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on.\n",
    "\n",
    "**Note:** This will delete the endpoind instance but will leave the model and results still stored in `S3`. Moreover, it will leave your Notebook instance still running. If you're concerned about the costs of these services, make sure to delete those as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: DEMO-ll-mni-2024-05-22-12-35-01-018\n",
      "INFO:sagemaker:Deleting endpoint configuration with name: DEMO-ll-mni-2024-05-22-12-14-42-006-06dabeeb\n",
      "INFO:sagemaker:Deleting endpoint with name: DEMO-ll-mni-2024-05-22-12-14-42-006-06dabeeb\n"
     ]
    }
   ],
   "source": [
    "linear_predictor.delete_model()\n",
    "linear_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

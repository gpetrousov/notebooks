{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "707bcdbe-22f0-49b3-8dc7-c659c2ea3431",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Minibatch\n",
    "\n",
    "\n",
    "Why are we re-writing things from scratch?\n",
    "\n",
    "The idea is that we're trying to learn a library better. If we can't learn what the library does,  we can just re-implement the algorithm ourselves and then we'll be able to understand the library's functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55fbab1c-8e99-4d54-944a-48ec19323069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| default_exp training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "571ce8f7-7911-4738-ad72-133c43e680a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import torch\n",
    "from torch import nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21342592-e550-4a31-a4ad-526e16381d28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the MNIST dataset\n",
    "import gzip, pickle\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MNIST_URL = \"https://github.com/mnielsen/neural-networks-and-deep-learning/blob/master/data/mnist.pkl.gz?raw=true\"\n",
    "data_path = Path(\"../data\")\n",
    "data_path.mkdir(parents=True, exist_ok=True)\n",
    "data_gz = data_path/\"mnist.pkl.gz\"\n",
    "\n",
    "# Get the data\n",
    "if not data_gz.exists():\n",
    "    urllib.request.urlretrieve(MNIST_URL, data_path/\"mnist.pkl.gz\")\n",
    "    \n",
    "# Destructuring\n",
    "with gzip.open(data_gz, mode='rb') as unzip_data:\n",
    "    obj = pickle.load(unzip_data, encoding=\"latin-1\")\n",
    "    ((x_train, y_train), (x_valid, y_valid), _) = obj\n",
    "\n",
    "# To tensors\n",
    "x_train, y_train, x_valid, y_valid = map(torch.tensor, (x_train, y_train, x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e20edea-32a5-4222-b178-084a0ffe33da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784, 10, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n, m = x_train.shape\n",
    "c = int(y_train.max()+1)\n",
    "nh = 50\n",
    "n, m, c, nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d3b312-bf06-4f05-85b9-b4bdd936c37a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Our model architecture from 03_backpropagation.ipynb\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [\n",
    "            nn.Linear(n_in, nh), # [784,50]\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nh, n_out) # [50,10]\n",
    "        ]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27adc51d-9e93-4b95-9363-34c03f952832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(m, nh, c)\n",
    "preds = model(x_train)\n",
    "preds.shape # We are now going to use 10 categories for output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c34768-f492-43cb-a0af-79f0046f223c",
   "metadata": {},
   "source": [
    "## Implement `Cross Entropy Loss` function\n",
    "\n",
    "In the last notebook, we used the MSE (L2-norm) to calculate the error. That function was not ideal for predicting multicategory classifications, like MNIST. Following, we are going to reconstruct the `cross entropy loss` function from scratch. \n",
    "\n",
    "The targets will be `on-hot-encoded` vectors with the index of a 1 representing the actual number.\n",
    "\n",
    "**`Cross Entropy Loss` typically serves multi-class and multi-label classifications.**\n",
    "\n",
    "`Cross Entropy Loss = log(SoftMax(i))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708c08b-4294-4008-9568-fd6fd6a9b39a",
   "metadata": {
    "tags": []
   },
   "source": [
    "First, we will need to compute the softmax of our activations. This is defined by:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{e^{x_{0}} + e^{x_{1}} + \\cdots + e^{x_{n-1}}}$$\n",
    "\n",
    "or more concisely:\n",
    "\n",
    "$$\\hbox{softmax(x)}_{i} = \\frac{e^{x_{i}}}{\\sum\\limits_{0 \\leq j \\lt n} e^{x_{j}}}$$ \n",
    "\n",
    "In practice, we will need the log of the softmax when we calculate the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c30ef424-4573-44a5-9da9-7817257cc995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# softmax: x.exp()/(x.exp().sum(dim=-1, keepdim=True))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\" Softmax \"\"\"\n",
    "    return (x.exp()/(x.exp().sum(dim=-1, keepdim=True))).log()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e07ebf3-40ac-4543-be54-abcccd956b7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "Note that the formula \n",
    "\n",
    "$$\\log \\left ( \\frac{a}{b} \\right ) = \\log(a) - \\log(b)$$ \n",
    "\n",
    "gives a simplification when we compute the log softmax:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d62f1635-6451-436d-ab2b-ef801fc87afb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#log(softmax(x)):\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1,keepdim=True).log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dac5435-ced7-4bf6-a6b3-465a67a01538",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3140, -2.4207, -2.4118,  ..., -2.4077, -2.2544, -2.1577],\n",
       "        [-2.3702, -2.2981, -2.4286,  ..., -2.4238, -2.2824, -2.0687],\n",
       "        [-2.2985, -2.4252, -2.3934,  ..., -2.4363, -2.2550, -2.1677],\n",
       "        ...,\n",
       "        [-2.2846, -2.3885, -2.3132,  ..., -2.4210, -2.3262, -2.1728],\n",
       "        [-2.3040, -2.4356, -2.4731,  ..., -2.4082, -2.2953, -2.1849],\n",
       "        [-2.3516, -2.3857, -2.3335,  ..., -2.4001, -2.2399, -2.1858]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_preds = log_softmax(preds)\n",
    "log_softmax_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83731144-ecc3-47ee-8a0b-7f6afede400b",
   "metadata": {},
   "source": [
    "The cross entropy loss for some target $x$ and some prediction $p(x)$ is given by:\n",
    "\n",
    "$$ -\\sum x\\, \\log p(x) $$\n",
    "\n",
    "In `PyTorch` this is known as : negative log likelihood loss == `nll`\n",
    "\n",
    "But since our $x$s are 1-hot encoded (actually, they're just the integer indices), this can be rewritten as $-\\log(p_{i})$ where i is the index of the desired target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807cfd21-17a2-4e8b-9b74-0187ae04b938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 3 numbers\n",
    "y_train[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b2013c7-e899-4279-9103-fce7ab8c98d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2c2b741-ab3d-470f-85f7-19a8d2e8ae10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.2620, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.3702, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.4032, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The prababilities of the categories from above are\n",
    "log_softmax_preds[0, 5], log_softmax_preds[1, 0], log_softmax_preds[2, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f900fddc-41ab-4ac7-bc07-766f95bb363d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.2620, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.3702, grad_fn=<SelectBackward0>),\n",
       " tensor(-2.4032, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_preds[0, y_train[0]], log_softmax_preds[1, y_train[1]], log_softmax_preds[2, y_train[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4751548-7589-41bb-b5a4-7a2df9d7e68f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2620, -2.3702, -2.4032], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_softmax_preds[[0,1,2], y_train[:3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c479ba9-c851-43ab-accb-60c0fc78598a",
   "metadata": {},
   "source": [
    "So, we have the `log(softmax(p))`. Now we need to implement the Cross entropy loss from above as the sum of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8f94afa-f14e-4203-a7b4-bce7c7ee01d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def nll(inp, target):\n",
    "    \"\"\" Cross Entropy Loss \"\"\"\n",
    "    return -inp[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e49fe07f-65be-49d9-a62f-86501697f504",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3058, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nll(log_softmax_preds, y_train)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57448954-1669-4a23-b31b-30c63c68ad16",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Going to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35c906e-4b44-4bd4-a726-89ea6e75746a",
   "metadata": {},
   "source": [
    "`PyTorch` already has a function for `Cross Entropy Loss`, so we can use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ef8efe8-3830-4b0e-b7d1-d5e9df840c7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3058, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# nll = negative log likelihood loss\n",
    "F.nll_loss(F.log_softmax(preds, dim=1), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb6e861-e21a-4ea0-9557-bd0adf4de8b3",
   "metadata": {},
   "source": [
    "The above combination of the 2 functions can be combined into 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "487d960c-da9e-4ad2-9a25-50ef2e878cca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3058, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(preds, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716f6b92-af96-4603-921e-741c3a5b01c0",
   "metadata": {},
   "source": [
    "## Basic training loop\n",
    "\n",
    "1) get the predictions from the model\n",
    "2) calculate the loss from the predictions (based on y_train)\n",
    "3) calculate the gradients of the loss with respect to every parameter of the model\n",
    "4) adjust the parameters according to their gradients and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dca9d642-5bc9-40c6-9aa3-23e136b27f1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa881109-ee28-487c-9f56-0cefacbc5c77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0060, -0.1127, -0.1038, -0.0005, -0.0785,  0.0460,  0.1590, -0.0996,\n",
       "          0.0537,  0.1504], grad_fn=<SelectBackward0>),\n",
       " torch.Size([64, 10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "xb = x_train[:bs] # minibatch from x\n",
    "preds = model(xb)\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f046e1c4-ac61-47f1-8917-6bf0a52492f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[:bs]\n",
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a79f255b-a44c-4926-b807-103aed69a9ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2974, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3635a4-7bb0-4149-a001-193b89a1b406",
   "metadata": {
    "tags": []
   },
   "source": [
    "We need to grab the highest probabilities of the predicted nubmers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f921d26-059d-4d99-b3b0-2f8e2e861e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 9, 6, 9, 9, 6, 6, 9, 6, 6, 6, 6, 6, 6, 6, 9, 6, 9, 6, 6, 8, 9, 6, 9,\n",
       "        6, 6, 6, 9, 6, 6, 6, 9, 6, 9, 9, 6, 6, 9, 6, 6, 6, 9, 9, 9, 6, 9, 6, 6,\n",
       "        6, 9, 9, 9, 9, 6, 9, 6, 9, 9, 9, 9, 6, 6, 6, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the indexes of the highest probabilities\n",
    "# preds.argmax(dim=1)\n",
    "preds.argmax(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8362455d-3fa0-419b-9e97-3966800aa603",
   "metadata": {},
   "source": [
    "And we define the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e4506e-24d5-4f31-b26b-a5c5b70e97b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def accuracy(preds, targs) -> float:\n",
    "    \"\"\" The average accuracy of the correctly predicted numbers \"\"\"\n",
    "    return (preds.argmax(dim=1)==targs).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8268c9f1-b240-4121-b0a1-dde89b17affb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1875)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c244910-25dc-4e1d-8fed-6c4c10fff62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def report(epoch:int, preds:torch.tensor, targs:torch.tensor, loss:float):\n",
    "    \"\"\" Print a report \"\"\"\n",
    "    print(f\"epoch:{epoch}\\n#-------------------------#\")\n",
    "    print(f\"accuracy:{accuracy(preds, targs).item():.3f} \\t loss:{loss.item():.5f}\")\n",
    "    print(\"#=========================#\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4bf2c580-ba44-4879-86b1-5c425a2017a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.188 \t loss:2.29740\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "xb, yb = x_train[:bs], y_train[:64]\n",
    "preds = model(xb)\n",
    "report(1, preds, yb, loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4d8c3-1587-479d-a2fd-7889d6140d86",
   "metadata": {},
   "source": [
    "Let's setup the basic training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2203c8da-124f-4efd-9f55-378740cdadcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Recreate the model before running the training\n",
    "model = Model(m, nh, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18d4cb29-f186-4617-99f4-14a2ae088046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 \t accuracy:0.937500 \t loss:0.303032\n",
      "epoch:1 \t accuracy:1.000000 \t loss:0.085718\n",
      "epoch:2 \t accuracy:1.000000 \t loss:0.075807\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 3\n",
    "lr = 0.5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for i in range(0, x_train.shape[0], batch_size):\n",
    "        \n",
    "        # Create xb, yb batch - this operation is way slower than slice\n",
    "        if i+batch_size > x_train.shape[0]:\n",
    "            xb = x_train[i:]\n",
    "            yb = y_train[i:]\n",
    "        else:\n",
    "            xb = x_train[i:i+batch_size] # x batch\n",
    "            yb = y_train[i:i+batch_size] # y batch\n",
    "            \n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, \"weight\"):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    print(f\"epoch:{epoch} \\t accuracy:{accuracy(preds, yb).item():.6f} \\t loss:{loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830b391-71ed-4a58-b650-865aebebc756",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using `slice`\n",
    "\n",
    "The `slice()` function returns a `slice object` that is used to slice any sequence (string, tuple, list, range, or bytes). So, we can use it to slice the training tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2712c226-61c2-4962-9245-375d797f5efa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(m, nh, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9186d6de-f896-4283-80b5-eac793197016",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.23894\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.13703\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.11017\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "bs = 64\n",
    "epochs = 3\n",
    "lr = 0.5\n",
    "n_inp = x_train.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n_inp, 64):\n",
    "        s = slice(i, min(n_inp, i + bs))\n",
    "        xb, yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, \"weight\"):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias -= l.bias.grad * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias.grad.zero_()\n",
    "    report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4062cd-8fa0-45e1-a9bf-73869919bbb7",
   "metadata": {},
   "source": [
    "### PyTorch parameters\n",
    "\n",
    "We are going to reduce the code size for the parameter update.\n",
    "\n",
    "If we create an object which inherits from `nn.Module`, we can assign arbitrary parameters to it and traverse them as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eba11b9c-f657-4d38-b119-15c961aec37e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Module(\n",
       "  (foo): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (bar): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = nn.Module()\n",
    "m1.foo = nn.Linear(3, 4)\n",
    "m1.bar = nn.Linear(4, 1)\n",
    "m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a9a08786-500e-489a-a17f-8e8e60330204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('foo', Linear(in_features=3, out_features=4, bias=True)),\n",
       " ('bar', Linear(in_features=4, out_features=1, bias=True))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This allows us to access the attributes of m1\n",
    "list(m1.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a0299eae-8091-41a6-b784-e3c6b3dff9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.3266,  0.3039,  0.5283],\n",
       "         [-0.2270, -0.3690, -0.0490],\n",
       "         [-0.3799,  0.0288,  0.1058],\n",
       "         [-0.4960,  0.1610, -0.5476]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4991, -0.1271,  0.4899, -0.2653], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0809, -0.4615,  0.4568,  0.2750]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4473], requires_grad=True)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This prints the weights and bias matrices\n",
    "list(m1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4502bac4-ad18-4e8f-a7d1-52d5d9bbf7a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple Multi Layer Perceptron to illustrate the use of parameter. \n",
    "    A MLP has a minimum of 3 layers which makes this one the simplest MLP.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in, nh)\n",
    "        self.l2 = nn.Linear(nh, n_out)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Forward pass \"\"\"\n",
    "        return self.l2(self.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cf5f17d-bf18-4c7e-a92b-881e7d5cd204",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MLP(m, nh, c)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3f55128d-2df0-459b-bb87-b639859d58c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n",
      "relu: ReLU()\n"
     ]
    }
   ],
   "source": [
    "for name, l in model.named_children():\n",
    "    print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf07a0f-e000-41f6-966c-a576e8b0864f",
   "metadata": {
    "tags": []
   },
   "source": [
    "You can access the parameteres (`weights` and `biases`) of each layer of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ecf5bb8f-90f7-4e1c-bdbc-bc1fcaf694bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e18ef-c1cc-485e-9f31-620ea430db57",
   "metadata": {},
   "source": [
    "That means, we can update them in the loop we hade defined before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f7ba91b-8c7e-41ba-98e5-cf0c42f353f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = MLP(m, nh, c)\n",
    "bs = 64\n",
    "epochs = 3\n",
    "lr = 0.5\n",
    "n_inp = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3bc366d7-a2d4-449e-a2c7-fe53cc530519",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit(model=model, epochs=3):\n",
    "    \"\"\" Basic loop using Torch model parameters to update their gradients. \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n_inp, bs):\n",
    "            s = slice(i, min(n_inp, i+bs))\n",
    "            xb = x_train[s]\n",
    "            yb = y_train[s]\n",
    "            preds = model(xb) # We are now using the MLP model\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad*lr\n",
    "                model.zero_grad() # Reset gradients for all model parameters\n",
    "        report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9211cdef-9694-4e34-83e0-6fef47ea52b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.20501\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.08821\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.06692\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49880cec-c432-4962-a632-68658265a0da",
   "metadata": {},
   "source": [
    "#### How it works in the background\n",
    "\n",
    "In the background `PyTorch` uses the `__setattr__()` function which allows you to set arbitrary object properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e610d333-6216-4e03-9473-2f0643b8b69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __setattr__(self, k, v):\n",
    "        \"\"\" This is how PyTorch.nn.Module stores the children of the model. \"\"\"\n",
    "        if not k.startswith(\"_\"):\n",
    "            self._modules[k] = v\n",
    "        super().__setattr__(k, v)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "    \n",
    "    def parameters(self):\n",
    "        \"\"\" How to traverse parametes \"\"\"\n",
    "        for l in self._modules.values():\n",
    "            yield from l.parameters()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4bcf22c1-f957-48e3-926d-a1744c0b02eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel = MyModule(m, nh, c)\n",
    "mymodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bb4b920-2837-4526-b79e-4f977752c985",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for p in mymodel.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3532e8c4-82b9-4684-8067-3bf5ea8dddb1",
   "metadata": {},
   "source": [
    "### Registering layers in model - from scratch\n",
    "\n",
    "How do we registers all the layers in our model at once - with `nn.Module`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9637faa8-6bdb-49d2-97f8-f5806d40aa1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Suppose we store the layers in a variable\n",
    "layers = [nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "46289d90-2417-4919-9684-f93c682baa24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i, l in enumerate(self.layers):\n",
    "            self.add_module(f\"layer_{i}\", l) # This adds the modules to the module\n",
    "            \n",
    "    def forward(self, x):\n",
    "        for l in self.layers:\n",
    "            x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d36a685f-a516-4f75-af42-864ea15a8fbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6906215-211a-4b1b-b932-c283771da10b",
   "metadata": {},
   "source": [
    "It's apparent that **we're building a sequential model**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4cbf73-6978-4fe5-b129-d31cf5f91847",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Going to PyTorch - `nn.ModuleList()`\n",
    "\n",
    "`PyTorch` allows use to add module with the `nn.ModuleList()` function.\n",
    "\n",
    "https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#modulelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75e9e879-2286-4b5d-8da3-348c55b14d97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SequentialModel(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.linears = nn.ModuleList(layers) # Create sequential model\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, l in enumerate(self.linears):\n",
    "            x = l(x)\n",
    "        return x\n",
    "        # return reduce(lambda val,layer: layer(val), self.layers, x)\n",
    "    # Python reduce: https://realpython.com/python-reduce-function/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc15addb-92de-4a72-9943-aff433a2929a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialModel(\n",
       "  (linears): ModuleList(\n",
       "    (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqmodel = SequentialModel(layers)\n",
    "seqmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "30f5c9fe-650d-4eb8-8b02-4072c28e083c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.26009\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.06191\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.06112\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit(model=seqmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6bc782-3db1-471b-a71d-f1ad70375d29",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Going to PyTorch - `nn.Sequential()`\n",
    "\n",
    "This is a convenience class which does the same thing as above - it registers our modules for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "097275c0-be0f-44d0-af77-245e1329d2e6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6e17ff4b-60e4-4c8d-b078-57e27ea6f827",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.21852\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.12376\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.06742\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bfe185-ceaa-439f-8057-8bea42d3e878",
   "metadata": {},
   "source": [
    "### SGD Optimizer - from scratch\n",
    "\n",
    "Finding the gradients of the layers and updating the parameters is a common step. An optimizer is a function which does that for us.\n",
    "\n",
    "```Python\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters():\n",
    "        p -= p.grad*lr\n",
    "    model.zero_grad() # Reset gradients for all model parameters\n",
    "```\n",
    "\n",
    "Let's create our own `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d930256a-2fcc-4ff8-9edd-09baf19c2691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SGD_Optimizer():\n",
    "    def __init__(self, params, lr=0.5):\n",
    "        self.params = list(params)\n",
    "        self.lr = lr\n",
    "        \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for p in self.params:\n",
    "                p -= p.grad * self.lr\n",
    "                \n",
    "    def zero_grad(self):\n",
    "        for p in self.params:\n",
    "            p.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ed54b23-9754-4437-9f78-6aa4a36005d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a016ea31-c812-44f2-b441-9822d2c57366",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create opt as an object of the model's parameters\n",
    "opt = SGD_Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1220c91a-aa78-4d14-8812-f7ed8a9afab3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.30260\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.12236\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.03961\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "# New training loop\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb = x_train[s]\n",
    "        yb = y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Out custom SGD optimizer\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5795599-cea4-4fe0-9d8b-f96c5ddef263",
   "metadata": {
    "tags": []
   },
   "source": [
    "PyTorch provides the same functionality with `optim.SGD` and it also provides the `momentum` parameter (which avoids local minimums during SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf08ae2-f3b0-4273-85e6-d803bc6feca0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Going to PyTorch - `optim.SGD`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4e0d1133-b626-4b8e-b90a-6edb3089be1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f9adc040-1c7d-410b-b25c-1919c52be9ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))\n",
    "opt = optim.SGD(model.parameters(), lr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b3ef14c-f08f-4c73-9975-a1ab0b284a98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.27220\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.10800\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.04318\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0, n, bs):\n",
    "        s = slice(i, min(i+bs, n))\n",
    "        xb = x_train[s]\n",
    "        yb = y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        # PyTorch's SGD optimizer\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3dbfb062-ba1f-438d-b183-1d978646564e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_lin_model():\n",
    "    \"\"\" Use PyTorch to create the smallest MLP and SGD optimizer. \"\"\"\n",
    "    _model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, c))\n",
    "    _opt = optim.SGD(_model.parameters(), lr=0.5)\n",
    "    return _model, _opt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3842aa-dbce-4951-a25a-08c4d33e4be0",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "\n",
    "We're going to create the `Dataset` and `DataLoader` from scratch to understand how they're implemented in `PyTorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0bb5bc-b130-4ffb-9dca-143fd81d5d00",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "We'll go from:\n",
    "\n",
    "```python\n",
    "s = slice(i, min(i+bs, n))\n",
    "xb = x_train[s]\n",
    "yb = y_train[s]\n",
    "```\n",
    "\n",
    "to\n",
    "\n",
    "```python\n",
    "xb,yb = train_ds[s]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "138e3750-e64b-4452-aac7-75cc029a15b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, s):\n",
    "        \"\"\" Slicing function: replaced slice() \"\"\"\n",
    "        return self.x[s], self.y[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a186c205-ed87-4e01-9f02-13f3bc0c55f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "assert len(train_ds) == len(x_train)\n",
    "assert len(valid_ds) == len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9e22da11-38f2-496f-ad66-024288c06871",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = train_ds[0:5]\n",
    "assert xb.shape == (5, 28*28)\n",
    "assert yb.shape == (5,)\n",
    "xb, yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7027e1b4-6f42-44ec-b199-5f495f07b083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, opt = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de2ccc36-758d-4768-91a6-0f95dc8d8294",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New fit function with Dataset class\n",
    "def fit(model = model, opt = opt):\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, n, bs):\n",
    "            xb, yb = train_ds[i:min(n, i+bs)]\n",
    "            preds = model(xb)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ad01d82f-878d-421d-b2c5-85169423255a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.20979\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.07331\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.03511\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105db3c3-1f15-4e8d-90ad-cdb45b0ea2f1",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "\n",
    "We are going to replace:\n",
    "\n",
    "```Python\n",
    "for i in range(0, n, bs):\n",
    "    xb, yb = train_ds[i:min(n, i+bs)]\n",
    "```\n",
    "with:\n",
    "```Python\n",
    "for xb, yb in train_dl:\n",
    "    ...\n",
    "```\n",
    "\n",
    "So we need to create an itterator with `__iter__()` and `yield`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7cbd67d1-3773-4353-b947-e64905bd287e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs):\n",
    "        self.ds = ds\n",
    "        self.bs = bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs):\n",
    "            yield self.ds[i:min(len(self.ds), i+self.bs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33330811-9123-47e3-8ec5-76ce4c2ee88d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "978daa37-7670-47c7-ab75-cb5966618092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c4512aad-f598-40fa-b39c-7d30e96a83a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "        1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9, 3, 9, 8, 5,\n",
       "        9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05de6684-0e80-4911-9d05-5125c7a46289",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6c6ed5f760>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[7].view(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e62c773a-5205-4a8f-823f-b32770b50613",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, opt = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "48c244c7-dbd0-4d72-b9a7-c4ec7d4bdea7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb, yb in train_dl:\n",
    "            preds = model(xb)\n",
    "            loss = F.cross_entropy(preds, yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        report(epoch, preds, yb, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4cdb2b70-0b8e-48f7-9c2e-a7f2c6f51a9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.10618\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.08907\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.05057\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b567e5-eae4-4681-9176-634167203a36",
   "metadata": {},
   "source": [
    "### Batch randomizer\n",
    "\n",
    "Now, we have created a way to load datasets into the traininig function. However, the DataLoaderes are sequential - they fetch items in a sequence.\n",
    "\n",
    "One feature we can add to the `DataLoader` is a shuffler, which fetches random data from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1728c9e5-e45f-4864-8d22-9ee4ab3019f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a69a98be-89b5-4f83-8a32-f76dd23961bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    \"\"\" Returns an iterator with optionally randomized indexes of the Dataset \"\"\"\n",
    "    def __init__(self, ds, shuffle=False):\n",
    "        self.n = len(ds)\n",
    "        self.shuffle = shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the indexes which we're going to use to create xb and yb \"\"\"\n",
    "        result = list(range(self.n))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(result)\n",
    "        return iter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "54852296-e71c-4510-9e6f-60e3b6e79047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "04b76b86-f2e9-4b7e-b6e7-b5fa91dfd9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds) # If shuffle==False\n",
    "list(islice(ss, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "103daefa-4a07-4157-98cf-a71887a6393d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14437, 40643, 43098, 13706, 2976]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = Sampler(train_ds, shuffle=True)\n",
    "list(islice(ss,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6a448c-ecce-4521-80ad-d9ed2e4c0dc0",
   "metadata": {},
   "source": [
    "Now we can create random indexes for a single batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "abd6c744-0bf3-406e-8a05-d1ce07fc0aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import fastcore.all as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dcd8dbaf-0735-464a-bd69-95c6d7cea4d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BatchSampler():\n",
    "    \"\"\" Creates batch size Sampler slices. \"\"\"\n",
    "    def __init__(self, sampler, bs, drop_last=False):\n",
    "        fc.store_attr()\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns batches of indexes of batch size \"\"\"\n",
    "        yield from fc.chunked(iter(self.sampler), self.bs, drop_last=self.drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6735a711-ff25-4111-af92-d48b83658d87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[44196, 16341, 11877, 24036, 42466],\n",
       " [5432, 11536, 35334, 33224, 26588],\n",
       " [34447, 44724, 35057, 36256, 4243],\n",
       " [28438, 30429, 2260, 14248, 34686],\n",
       " [22293, 49766, 14793, 38714, 29053],\n",
       " [36077, 34203, 29360, 32278, 40332],\n",
       " [5545, 20410, 49432, 12878, 14760],\n",
       " [47476, 16030, 39703, 18614, 22381],\n",
       " [25091, 20780, 14741, 19372, 17125],\n",
       " [38155, 7282, 40525, 18624, 31133]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchs = BatchSampler(ss, 5)\n",
    "list(islice(batchs, 10))\n",
    "# Now we can generate x amount of randomized indexes of batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe147c88-7334-4891-bedd-88b618f6e545",
   "metadata": {},
   "source": [
    "Now we can create batches of random indexes using `Sampler()` and `BatchSampler()`.\n",
    "\n",
    "However, we need to be returning `torch.Tensors`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "903d07d6-de03-4c90-b119-1713d60e2244",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    \"\"\" Splits the x and y into the different tensors \"\"\"\n",
    "    # import pdb\n",
    "    # pdb.set_trace()\n",
    "    xs, ys = zip(*b)\n",
    "    return torch.stack(xs), torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d2a28620-0c80-426a-97a3-c1eb723f95c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  3.,  6., 10.],\n",
       "        [ 0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.,3.,6.,10.])\n",
    "b = torch.tensor([0, 0, 0, 0, ])\n",
    "torch.stack((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d55a55e0-8fe1-4e49-9bf6-2813bfe04402",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, batchs, collate_fn=collate):\n",
    "        fc.store_attr() # Stores everything in __init__() in a self variable\n",
    "        \n",
    "    def __iter__(self):\n",
    "        yield from (self.collate_fn(self.ds[i] for i in b) for b in self.batchs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bc84ce07-5e5c-4eb8-8b9b-c71409f08e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4]))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6c5b59c2-81ad-4fc7-8a6b-771fe59f4ed4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the batch size indexes\n",
    "train_sample = BatchSampler(Sampler(train_ds, shuffle=True), bs)\n",
    "valid_sample = BatchSampler(Sampler(train_ds, shuffle=False), bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bfdb0225-5d8b-4d87-97e4-554a6b34fc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[49326,\n",
       "  25263,\n",
       "  19786,\n",
       "  22147,\n",
       "  36522,\n",
       "  27160,\n",
       "  27634,\n",
       "  42238,\n",
       "  23976,\n",
       "  13867,\n",
       "  41254,\n",
       "  49616,\n",
       "  8309,\n",
       "  17869,\n",
       "  35529,\n",
       "  35962,\n",
       "  17135,\n",
       "  5378,\n",
       "  34730,\n",
       "  18490,\n",
       "  38723,\n",
       "  26186,\n",
       "  43456,\n",
       "  25266,\n",
       "  41020,\n",
       "  4038,\n",
       "  14793,\n",
       "  35136,\n",
       "  31498,\n",
       "  44424,\n",
       "  33708,\n",
       "  7996,\n",
       "  20744,\n",
       "  12449,\n",
       "  13641,\n",
       "  35204,\n",
       "  28620,\n",
       "  11220,\n",
       "  3630,\n",
       "  31397,\n",
       "  15565,\n",
       "  12078,\n",
       "  14297,\n",
       "  12219,\n",
       "  5153,\n",
       "  48505,\n",
       "  49606,\n",
       "  38689,\n",
       "  23023,\n",
       "  3132,\n",
       "  26306,\n",
       "  22436,\n",
       "  35096,\n",
       "  49997,\n",
       "  47756,\n",
       "  47879,\n",
       "  3749,\n",
       "  29208,\n",
       "  11576,\n",
       "  23252,\n",
       "  3987,\n",
       "  22529,\n",
       "  10571,\n",
       "  26010]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(islice(train_sample, 1)) # 1x64 list of randomized indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "204da9ec-0297-497e-a949-76cf8b44954f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the actual iterators over the training and validation Datasets\n",
    "train_dl = DataLoader(train_ds, batchs=train_sample)\n",
    "valid_dl = DataLoader(valid_ds, batchs=valid_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce94bd11-57ac-47fd-abbf-cfe3beb21fa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xb, yb = next(iter(train_dl)) # That should fetch an xb shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2612e162-d899-4e4d-b8de-20318234a4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb.shape, yb.shape # These are randomized training tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "48d25ef6-b076-43ba-b3a8-e270dfa58ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x7f6c6eaf6170>, tensor(3))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[50].view(28, 28), cmap=\"gray\"), yb[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e60de7b2-df23-4304-a18e-0d618e0e4891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model, opt = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7b038c2d-7d19-481b-80ac-6309245351e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.750 \t loss:0.55483\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.17745\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.00661\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b15653-5604-49ab-aebc-4c35b4b6c3cd",
   "metadata": {},
   "source": [
    "The `PyTorch`'s `DataLoaders` work exactly like the implementation above. However, it runs in parallel when the `DataLoader` class.\n",
    "\n",
    "**I skipped implementing the parallel `DataLoader`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca213d4-e55e-4aac-a825-819704615d6e",
   "metadata": {},
   "source": [
    "### Going to `PyTorch` `DataLoader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b590b749-98a5-4d42-827b-2902eb1407b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler, BatchSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c4fab000-7097-45fb-8d46-c980d2790c8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the batch size indexes\n",
    "train_sample = BatchSampler(RandomSampler(train_ds),     bs, drop_last=False)\n",
    "valid_sample = BatchSampler(SequentialSampler(valid_ds), bs, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "306b7f5a-5708-4abc-b1cf-ac5f56cec2fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the DataLoaders using the indexes from above\n",
    "train_dl = DataLoader(train_ds, batch_sampler=train_sample, collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, batch_sampler=valid_sample, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9c0b9472-15a6-44f2-bcb1-a8e026412511",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.05168\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.07762\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.04102\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_lin_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09deec4d-224c-4a5a-8178-23b3d6344f70",
   "metadata": {},
   "source": [
    "OR\n",
    "\n",
    "PyTorch's `DataLoader` can create the (random) batch samples for us - so we can use it directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "418aa2da-302d-430e-a3fb-278279873614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "74d102ea-3dbc-4a77-b337-b623337152ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.10885\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.06044\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:0.938 \t loss:0.60376\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_lin_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbed9c4-b7ce-4bb8-9dd2-a817c0d2f8db",
   "metadata": {},
   "source": [
    "`PyTorch` `DataLoader` can perform the random batch sampling without the having to explicitly create the `RandomSampler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f751dfbf-7c47-441b-8b6d-54490a93ab9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False, drop_last=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9d89cb34-506f-493a-b98f-4ed3844f0c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 784]), torch.Size([64]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb, yb = next(iter(train_dl))\n",
    "xb.shape, yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6a4bf072-817d-4bbe-8f76-18185c1e3adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.969 \t loss:0.07596\n",
      "#=========================#\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.03351\n",
      "#=========================#\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:1.000 \t loss:0.01672\n",
      "#=========================#\n"
     ]
    }
   ],
   "source": [
    "model, opt, get_lin_model()\n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9778cf-2500-4e0c-b931-99be74b27922",
   "metadata": {},
   "source": [
    "## Validation\n",
    "\n",
    "We've improved out basic training loop. Now, we need to see how it's performing on the validation dataset.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c46399a6-85e4-4cb5-9b5d-514746caa0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = torch.Tensor([1,2,3,4])\n",
    "T2 = torch.Tensor([5,6, 7,8])\n",
    "T3 = torch.Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "60e1ff6f-886d-4d38-9d9f-98bca61d56e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T3 = torch.cat((T3, T1), dim=0)\n",
    "T3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83aaa459-efa8-40a6-80c2-d919d63c3ffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        \n",
    "        epoch_total_loss = 0\n",
    "        nof_samples = 0\n",
    "        cumulative_preds = torch.Tensor()\n",
    "        cumulative_targs = torch.Tensor()\n",
    "        \n",
    "        for xb, yb in train_dl:\n",
    "            train_preds = model(xb)\n",
    "            cumulative_preds = torch.cat((cumulative_preds, train_preds))\n",
    "            cumulative_targs = torch.cat((cumulative_targs, yb))\n",
    "            train_loss = loss_func(train_preds, yb)\n",
    "            nof_samples += 1\n",
    "            epoch_total_loss += train_loss\n",
    "            train_loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        print(\"Training report\")\n",
    "        report(epoch, cumulative_preds, cumulative_targs, epoch_total_loss/nof_samples)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss, tot_acc, count = 0.,0.,0\n",
    "            for xb, yb in valid_dl:\n",
    "                valid_preds = model(xb)\n",
    "                n = len(xb)\n",
    "                count += n\n",
    "                tot_loss += loss_func(valid_preds, yb).item()*n # Why multiply?\n",
    "                tot_acc += accuracy(valid_preds, yb)*n\n",
    "        print(\"Validation report\")\n",
    "        print(f\"valid accuracy: {tot_acc/count:.3}\\t valid loss: {tot_loss/count:.3}\\n\")\n",
    "    return tot_loss/count, tot_acc/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "02040f74-2840-484a-9ebf-c74a5aa702e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#|export\n",
    "def get_dls(train_ds, valid_ds, bs, **kwargs):\n",
    "    train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True, num_workers=2, **kwargs)\n",
    "    valid_dl = DataLoader(valid_ds, bs, shuffle=False, num_workers=2, **kwargs)\n",
    "    return(train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "88cb5820-50ef-47b8-b20f-3a7ec15f0ca1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model, opt = get_lin_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "671c03d9-eeeb-4895-8405-3a2d1802251f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training report\n",
      "epoch:0\n",
      "#-------------------------#\n",
      "accuracy:0.905 \t loss:0.31069\n",
      "#=========================#\n",
      "Validation report\n",
      "valid accuracy: 0.954\t valid loss: 0.16\n",
      "\n",
      "Training report\n",
      "epoch:1\n",
      "#-------------------------#\n",
      "accuracy:0.956 \t loss:0.14337\n",
      "#=========================#\n",
      "Validation report\n",
      "valid accuracy: 0.969\t valid loss: 0.115\n",
      "\n",
      "Training report\n",
      "epoch:2\n",
      "#-------------------------#\n",
      "accuracy:0.967 \t loss:0.10780\n",
      "#=========================#\n",
      "Validation report\n",
      "valid accuracy: 0.968\t valid loss: 0.109\n",
      "\n",
      "Training report\n",
      "epoch:3\n",
      "#-------------------------#\n",
      "accuracy:0.973 \t loss:0.08703\n",
      "#=========================#\n",
      "Validation report\n",
      "valid accuracy: 0.971\t valid loss: 0.108\n",
      "\n",
      "Training report\n",
      "epoch:4\n",
      "#-------------------------#\n",
      "accuracy:0.977 \t loss:0.07425\n",
      "#=========================#\n",
      "Validation report\n",
      "valid accuracy: 0.973\t valid loss: 0.103\n",
      "\n",
      "CPU times: user 18.1 s, sys: 932 ms, total: 19 s\n",
      "Wall time: 5.03 s\n"
     ]
    }
   ],
   "source": [
    "%time loss, acc = fit(5, model, F.cross_entropy, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327f734-670c-4262-8b99-10311781355b",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1278679a-8dda-4089-b1d8-fab03b5a6a6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5deb55c3-b009-40fa-8257-82ddb973a037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
